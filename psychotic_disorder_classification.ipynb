{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6C0abbU4llQB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# The deep learning model was trained using Keras functional API, \n",
        "# running on top of TensorFlow in Google Colaboratory online platform \n",
        "# with Python 3.6 notebook.\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model, Model, Sequential\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten, Input, MaxPool2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaWvpZE3Wr5K"
      },
      "source": [
        "**About the original paper:**\n",
        "*   Title: Application of deep and machine learning techniques for multi-label classification performance on psychotic disorder diseases\n",
        "*   Authors: Israel Elujide, Stephen G. Fashoto, Bunmi Fashoto, Elliot Mbunge, Sakinat O. Folorunso, Jeremiah O. Olamijuwon\n",
        "*   Dataset: The data were obtained from Yaba Psychiatry Hospital, Yaba, Lagos State, Nigeria by Adejumo et al.\n",
        "*   Link: https://www.sciencedirect.com/science/article/pii/S2352914821000356"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkCkub0ZWr5M"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GmhbuUoWr5M"
      },
      "source": [
        "**Basic**\n",
        "\n",
        "Process the file:\n",
        "*   from google.colab import files\n",
        "\n",
        "Process the data:\n",
        "*   import numpy as np\n",
        "*   import pandas as pd\n",
        "\n",
        "Split data into train and test subsets:\n",
        "*   from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "**Balancing data**\n",
        "\n",
        "*   from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "**Machine learning**\n",
        "\n",
        "*   from sklearn.neural_network import MLPClassifier\n",
        "*   from sklearn.svm import LinearSVC\n",
        "*   from sklearn.ensemble import RandomForestClassifier\n",
        "*   from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "**Deep learning**\n",
        "\n",
        "Keras funtional API:\n",
        "*   from tensorflow import keras\n",
        "*   from keras.models import load_model, Model, Sequential # Sequential groups a linear stack of layers into a tf.keras.Model.\n",
        "*   from keras.layers import Conv2D, Dense, Dropout, Flatten, Input, MaxPool2D\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiTPtLRLmIy4"
      },
      "source": [
        "# Import Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAKMBmL5uDPC"
      },
      "source": [
        "**How to access to the dataset:**\n",
        "\n",
        "Please go the Appendix A of the [paper](https://www.sciencedirect.com/science/article/pii/S2352914821000356#cebib0010) or download through this [link](https://www.sciencedirect.com/science/article/pii/S2352340917303487#ec0010):\n",
        "\n",
        "\n",
        "*   In the section 'Extras', please click on 'Download all' to get the cvs file.\n",
        "*   Click on 'Choose Files' to upload the csv file here.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jJ0IDlaamHgk"
      },
      "outputs": [],
      "source": [
        "# Upload data file if using google colab\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# df = pd.read_csv(io.BytesIO(uploaded['data.csv']),encoding='cp1252')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzemldxYWr5P",
        "outputId": "40eb0b18-05eb-410d-9c99-67b7fb8626d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "path = \"/content/drive/MyDrive/data.csv\"\n",
        "\n",
        "df = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "mO0ORMD7mljl",
        "outputId": "b7afa411-37ec-4ff3-818b-f3286b7e2f0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sex  age faNoily_status religion occupation genetic status loss_of_parent  \\\n",
              "0     M   18            Yes        C    STUDENT     Yes      S            Yes   \n",
              "1     F   30            Yes        M    ARTISAN     Yes      S            Yes   \n",
              "2     M   22            Yes        C    STUDENT      No      S             No   \n",
              "3     M   35             No        M    ARTISAN      No      M             No   \n",
              "4     M   30            Yes        M    ARTISAN     Yes      M             No   \n",
              "..   ..  ...            ...      ...        ...     ...    ...            ...   \n",
              "495   F   73            Yes        M    RETIRED     Yes      S            Yes   \n",
              "496   F   50             No        M    ARTISAN      No      M            Yes   \n",
              "497   F   32             No        C      FORCE      No      M             No   \n",
              "498   M   13            Yes        C    STUDENT      No      S            Yes   \n",
              "499   F   19            Yes        M    STUDENT      No      S            Yes   \n",
              "\n",
              "    divorse Injury Spiritual_consult Insominia shizopherania vascula_demetia  \\\n",
              "0        No     No               Yes         N             P               P   \n",
              "1        No    Yes               Yes         P             P               P   \n",
              "2        No     No               Yes         P             P               P   \n",
              "3        No     No               Yes         P             P               N   \n",
              "4        No     No               Yes         P             P               P   \n",
              "..      ...    ...               ...       ...           ...             ...   \n",
              "495      No     No               Yes         P             N               P   \n",
              "496      No     No                No         P             P               N   \n",
              "497      No     No               Yes         N             P               P   \n",
              "498      No     No                No         N             P               N   \n",
              "499      No     No               Yes         N             P               P   \n",
              "\n",
              "    MBD Bipolar  agecode  \n",
              "0     P       N        1  \n",
              "1     N       N        1  \n",
              "2     N       P        1  \n",
              "3     N       P        2  \n",
              "4     P       P        1  \n",
              "..   ..     ...      ...  \n",
              "495   N       P        3  \n",
              "496   P       P        2  \n",
              "497   P       N        2  \n",
              "498   N       N        1  \n",
              "499   N       N        1  \n",
              "\n",
              "[500 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c2d8f70-d0c8-457d-84fd-7f775628cba3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>faNoily_status</th>\n",
              "      <th>religion</th>\n",
              "      <th>occupation</th>\n",
              "      <th>genetic</th>\n",
              "      <th>status</th>\n",
              "      <th>loss_of_parent</th>\n",
              "      <th>divorse</th>\n",
              "      <th>Injury</th>\n",
              "      <th>Spiritual_consult</th>\n",
              "      <th>Insominia</th>\n",
              "      <th>shizopherania</th>\n",
              "      <th>vascula_demetia</th>\n",
              "      <th>MBD</th>\n",
              "      <th>Bipolar</th>\n",
              "      <th>agecode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>18</td>\n",
              "      <td>Yes</td>\n",
              "      <td>C</td>\n",
              "      <td>STUDENT</td>\n",
              "      <td>Yes</td>\n",
              "      <td>S</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>F</td>\n",
              "      <td>30</td>\n",
              "      <td>Yes</td>\n",
              "      <td>M</td>\n",
              "      <td>ARTISAN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>S</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>22</td>\n",
              "      <td>Yes</td>\n",
              "      <td>C</td>\n",
              "      <td>STUDENT</td>\n",
              "      <td>No</td>\n",
              "      <td>S</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>35</td>\n",
              "      <td>No</td>\n",
              "      <td>M</td>\n",
              "      <td>ARTISAN</td>\n",
              "      <td>No</td>\n",
              "      <td>M</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>30</td>\n",
              "      <td>Yes</td>\n",
              "      <td>M</td>\n",
              "      <td>ARTISAN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>M</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>F</td>\n",
              "      <td>73</td>\n",
              "      <td>Yes</td>\n",
              "      <td>M</td>\n",
              "      <td>RETIRED</td>\n",
              "      <td>Yes</td>\n",
              "      <td>S</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>F</td>\n",
              "      <td>50</td>\n",
              "      <td>No</td>\n",
              "      <td>M</td>\n",
              "      <td>ARTISAN</td>\n",
              "      <td>No</td>\n",
              "      <td>M</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>F</td>\n",
              "      <td>32</td>\n",
              "      <td>No</td>\n",
              "      <td>C</td>\n",
              "      <td>FORCE</td>\n",
              "      <td>No</td>\n",
              "      <td>M</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>M</td>\n",
              "      <td>13</td>\n",
              "      <td>Yes</td>\n",
              "      <td>C</td>\n",
              "      <td>STUDENT</td>\n",
              "      <td>No</td>\n",
              "      <td>S</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>F</td>\n",
              "      <td>19</td>\n",
              "      <td>Yes</td>\n",
              "      <td>M</td>\n",
              "      <td>STUDENT</td>\n",
              "      <td>No</td>\n",
              "      <td>S</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 17 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c2d8f70-d0c8-457d-84fd-7f775628cba3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c2d8f70-d0c8-457d-84fd-7f775628cba3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c2d8f70-d0c8-457d-84fd-7f775628cba3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDnU2cE7Pny3",
        "outputId": "e9151116-8a57-4e72-a47c-050663b8a3c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'N', 'P'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "set(df['Bipolar'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQTqP1qbRF5E"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37rp6d_4v4uh"
      },
      "source": [
        "**Encode data**\n",
        "\n",
        "\n",
        "*   The Negative or N values are encoded as 0 and the Positive or P values are encoded as 1.\n",
        "*   Add 'target' column with all combinations with more than 6 occurrences.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "1dmGaTGoPsjW",
        "outputId": "87145704-fd92-4f12-ff01-93931c7927a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sex  age  faNoily_status  genetic  status  loss_of_parent  divorse  \\\n",
              "0      1   18               1        1       1               1        0   \n",
              "1      0   30               1        1       1               1        0   \n",
              "2      1   22               1        0       1               0        0   \n",
              "3      1   35               0        0       0               0        0   \n",
              "4      1   30               1        1       0               0        0   \n",
              "..   ...  ...             ...      ...     ...             ...      ...   \n",
              "495    0   73               1        1       1               1        0   \n",
              "496    0   50               0        0       0               1        0   \n",
              "497    0   32               0        0       0               0        0   \n",
              "498    1   13               1        0       1               1        0   \n",
              "499    0   19               1        0       1               1        0   \n",
              "\n",
              "     Injury  Spiritual_consult  Insominia  ...  religion_O  \\\n",
              "0         0                  1          0  ...           0   \n",
              "1         1                  1          1  ...           0   \n",
              "2         0                  1          1  ...           0   \n",
              "3         0                  1          1  ...           0   \n",
              "4         0                  1          1  ...           0   \n",
              "..      ...                ...        ...  ...         ...   \n",
              "495       0                  1          1  ...           0   \n",
              "496       0                  0          1  ...           0   \n",
              "497       0                  1          0  ...           0   \n",
              "498       0                  0          0  ...           0   \n",
              "499       0                  1          0  ...           0   \n",
              "\n",
              "     occupation_ARTISAN  occupation_C/SERVANT  occupation_FORCE  \\\n",
              "0                     0                     0                 0   \n",
              "1                     1                     0                 0   \n",
              "2                     0                     0                 0   \n",
              "3                     1                     0                 0   \n",
              "4                     1                     0                 0   \n",
              "..                  ...                   ...               ...   \n",
              "495                   0                     0                 0   \n",
              "496                   1                     0                 0   \n",
              "497                   0                     0                 1   \n",
              "498                   0                     0                 0   \n",
              "499                   0                     0                 0   \n",
              "\n",
              "     occupation_RETIRED  occupation_STUDENT  occupation_UNEMPLYD  agecode_1  \\\n",
              "0                     0                   1                    0          1   \n",
              "1                     0                   0                    0          1   \n",
              "2                     0                   1                    0          1   \n",
              "3                     0                   0                    0          0   \n",
              "4                     0                   0                    0          1   \n",
              "..                  ...                 ...                  ...        ...   \n",
              "495                   1                   0                    0          0   \n",
              "496                   0                   0                    0          0   \n",
              "497                   0                   0                    0          0   \n",
              "498                   0                   1                    0          1   \n",
              "499                   0                   1                    0          1   \n",
              "\n",
              "     agecode_2  agecode_3  \n",
              "0            0          0  \n",
              "1            0          0  \n",
              "2            0          0  \n",
              "3            1          0  \n",
              "4            0          0  \n",
              "..         ...        ...  \n",
              "495          0          1  \n",
              "496          1          0  \n",
              "497          1          0  \n",
              "498          0          0  \n",
              "499          0          0  \n",
              "\n",
              "[500 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-182d8fad-5648-4f1b-ba9b-49ccb1c88536\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>faNoily_status</th>\n",
              "      <th>genetic</th>\n",
              "      <th>status</th>\n",
              "      <th>loss_of_parent</th>\n",
              "      <th>divorse</th>\n",
              "      <th>Injury</th>\n",
              "      <th>Spiritual_consult</th>\n",
              "      <th>Insominia</th>\n",
              "      <th>...</th>\n",
              "      <th>religion_O</th>\n",
              "      <th>occupation_ARTISAN</th>\n",
              "      <th>occupation_C/SERVANT</th>\n",
              "      <th>occupation_FORCE</th>\n",
              "      <th>occupation_RETIRED</th>\n",
              "      <th>occupation_STUDENT</th>\n",
              "      <th>occupation_UNEMPLYD</th>\n",
              "      <th>agecode_1</th>\n",
              "      <th>agecode_2</th>\n",
              "      <th>agecode_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>0</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-182d8fad-5648-4f1b-ba9b-49ccb1c88536')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-182d8fad-5648-4f1b-ba9b-49ccb1c88536 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-182d8fad-5648-4f1b-ba9b-49ccb1c88536');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "## Binary and One-hot encoding for categorial variables\n",
        "\n",
        "# Encode 'sex' (F/M) into binary value\n",
        "df['sex'].replace(['F', 'M'], [0, 1], inplace=True)\n",
        "\n",
        "# Encode 'faNoily_status' (No/Yes) into binary value\n",
        "df['faNoily_status'].replace(['No', 'Yes'], [0, 1], inplace=True)\n",
        "\n",
        "# Encode 'genetic' (No/Yes) into binary value\n",
        "df['genetic'].replace(['No', 'Yes'], [0, 1], inplace=True)\n",
        "\n",
        "# Encode 'status' (M/S) into binary value\n",
        "df['status'].replace(['M', 'S'], [0, 1], inplace=True)\n",
        "\n",
        "# Encode 'loss_of_parent' (No/Yes) into binary value\n",
        "df['loss_of_parent'].replace(['No', 'Yes'], [0, 1], inplace=True)\n",
        "\n",
        "# Encode 'divorse' (No/Yes) into binary value\n",
        "df['divorse'].replace(['No', 'Yes'], [0, 1], inplace=True)\n",
        "\n",
        "# Encode 'Injury' (No/Yes) into binary value\n",
        "df['Injury'].replace(['No', 'Yes'], [0, 1], inplace=True)\n",
        "\n",
        "# Encode 'Spiritual_consult' (No/Yes) into binary value\n",
        "df['Spiritual_consult'].replace(['No', 'Yes'], [0, 1], inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# region\n",
        "dum_religion = pd.get_dummies(df.religion, prefix='religion')\n",
        "df = pd.concat([df, dum_religion], axis=1)\n",
        "df.drop('religion', inplace=True, axis=1)\n",
        "\n",
        "# occupation\n",
        "dum_occ = pd.get_dummies(df.occupation, prefix='occupation')\n",
        "df = pd.concat([df, dum_occ], axis=1)\n",
        "df.drop('occupation', inplace=True, axis=1)\n",
        "\n",
        "# agecode\n",
        "dum_agecode = pd.get_dummies(df.agecode, prefix='agecode')\n",
        "df = pd.concat([df, dum_agecode], axis=1)\n",
        "df.drop('agecode', inplace=True, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "# Insominia (N/P)\n",
        "df['Insominia'].replace(['N', 'P'], [0, 1], inplace=True)\n",
        "\n",
        "# MBD (N/P)\n",
        "df['MBD'].replace(['N', 'P'], [0, 1], inplace=True)\n",
        "\n",
        "# Bipolar (N/P)\n",
        "df['Bipolar'].replace(['N', 'P'], [0, 1], inplace=True)\n",
        "\n",
        "# shizopherania (N/P)\n",
        "df['shizopherania'].replace(['N', 'P'], [0, 1], inplace=True)\n",
        "\n",
        "# vascula_demetia (N/P)\n",
        "df['vascula_demetia'].replace(['N', 'P'], [0, 1], inplace=True)\n",
        "\n",
        "data_original = df.copy()\n",
        "\n",
        "data_original"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qlu4QINEwlLl"
      },
      "source": [
        "Our target variables are in this order: Insomnia, schizophrenia, vascular dementia, ADHD and Bi-polar disorder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "m5u4fAP2SrGF",
        "outputId": "74fadba2-09be-4958-9842-b8d8ca2ec726"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sex  age  faNoily_status  genetic  status  loss_of_parent  divorse  \\\n",
              "0      1   18               1        1       1               1        0   \n",
              "1      0   30               1        1       1               1        0   \n",
              "2      1   22               1        0       1               0        0   \n",
              "3      1   35               0        0       0               0        0   \n",
              "4      1   30               1        1       0               0        0   \n",
              "..   ...  ...             ...      ...     ...             ...      ...   \n",
              "495    0   73               1        1       1               1        0   \n",
              "496    0   50               0        0       0               1        0   \n",
              "497    0   32               0        0       0               0        0   \n",
              "498    1   13               1        0       1               1        0   \n",
              "499    0   19               1        0       1               1        0   \n",
              "\n",
              "     Injury  Spiritual_consult  Insominia  ...  occupation_ARTISAN  \\\n",
              "0         0                  1          0  ...                   0   \n",
              "1         1                  1          1  ...                   1   \n",
              "2         0                  1          1  ...                   0   \n",
              "3         0                  1          1  ...                   1   \n",
              "4         0                  1          1  ...                   1   \n",
              "..      ...                ...        ...  ...                 ...   \n",
              "495       0                  1          1  ...                   0   \n",
              "496       0                  0          1  ...                   1   \n",
              "497       0                  1          0  ...                   0   \n",
              "498       0                  0          0  ...                   0   \n",
              "499       0                  1          0  ...                   0   \n",
              "\n",
              "     occupation_C/SERVANT  occupation_FORCE  occupation_RETIRED  \\\n",
              "0                       0                 0                   0   \n",
              "1                       0                 0                   0   \n",
              "2                       0                 0                   0   \n",
              "3                       0                 0                   0   \n",
              "4                       0                 0                   0   \n",
              "..                    ...               ...                 ...   \n",
              "495                     0                 0                   1   \n",
              "496                     0                 0                   0   \n",
              "497                     0                 1                   0   \n",
              "498                     0                 0                   0   \n",
              "499                     0                 0                   0   \n",
              "\n",
              "     occupation_STUDENT  occupation_UNEMPLYD  agecode_1  agecode_2  agecode_3  \\\n",
              "0                     1                    0          1          0          0   \n",
              "1                     0                    0          1          0          0   \n",
              "2                     1                    0          1          0          0   \n",
              "3                     0                    0          0          1          0   \n",
              "4                     0                    0          1          0          0   \n",
              "..                  ...                  ...        ...        ...        ...   \n",
              "495                   0                    0          0          0          1   \n",
              "496                   0                    0          0          1          0   \n",
              "497                   0                    0          0          1          0   \n",
              "498                   1                    0          1          0          0   \n",
              "499                   1                    0          1          0          0   \n",
              "\n",
              "     target  \n",
              "0     01110  \n",
              "1     11100  \n",
              "2     11101  \n",
              "3     11001  \n",
              "4     11111  \n",
              "..      ...  \n",
              "495   10101  \n",
              "496   11011  \n",
              "497   01110  \n",
              "498   01000  \n",
              "499   01100  \n",
              "\n",
              "[500 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04d93f61-f6d5-4f2f-be3e-4a70b6b45c3f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>faNoily_status</th>\n",
              "      <th>genetic</th>\n",
              "      <th>status</th>\n",
              "      <th>loss_of_parent</th>\n",
              "      <th>divorse</th>\n",
              "      <th>Injury</th>\n",
              "      <th>Spiritual_consult</th>\n",
              "      <th>Insominia</th>\n",
              "      <th>...</th>\n",
              "      <th>occupation_ARTISAN</th>\n",
              "      <th>occupation_C/SERVANT</th>\n",
              "      <th>occupation_FORCE</th>\n",
              "      <th>occupation_RETIRED</th>\n",
              "      <th>occupation_STUDENT</th>\n",
              "      <th>occupation_UNEMPLYD</th>\n",
              "      <th>agecode_1</th>\n",
              "      <th>agecode_2</th>\n",
              "      <th>agecode_3</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>01110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>0</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>01110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>01000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>01100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04d93f61-f6d5-4f2f-be3e-4a70b6b45c3f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-04d93f61-f6d5-4f2f-be3e-4a70b6b45c3f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-04d93f61-f6d5-4f2f-be3e-4a70b6b45c3f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data = df.copy()\n",
        "data['target'] = data['Insominia'].astype(str) + data['shizopherania'].astype(str) + data['vascula_demetia'].astype(str) + data['MBD'].astype(str) + data['Bipolar'].astype(str)\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1_tKsdzPafM5"
      },
      "outputs": [],
      "source": [
        "# Paper page 9 - \"As such, we removed all combinations with less than 6 occurrences.\"\n",
        "data = data.groupby('target').filter(lambda x: len(x) > 6)\n",
        "\n",
        "imbalanced_data = data.copy()\n",
        "# we have 'target' for these values\n",
        "del imbalanced_data['Insominia']\n",
        "del imbalanced_data['shizopherania']\n",
        "del imbalanced_data['vascula_demetia']\n",
        "del imbalanced_data['MBD']\n",
        "del imbalanced_data['Bipolar']\n",
        "\n",
        "balanced_data = data.copy()\n",
        "\n",
        "del data['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "mhyTpoJ87nuO",
        "outputId": "89b3cd2e-b9e6-4cf6-826c-e6a3bdfc1ae1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sex  age  faNoily_status  genetic  status  loss_of_parent  divorse  \\\n",
              "0      1   18               1        1       1               1        0   \n",
              "2      1   22               1        0       1               0        0   \n",
              "3      1   35               0        0       0               0        0   \n",
              "4      1   30               1        1       0               0        0   \n",
              "5      0   86               1        0       0               1        0   \n",
              "..   ...  ...             ...      ...     ...             ...      ...   \n",
              "495    0   73               1        1       1               1        0   \n",
              "496    0   50               0        0       0               1        0   \n",
              "497    0   32               0        0       0               0        0   \n",
              "498    1   13               1        0       1               1        0   \n",
              "499    0   19               1        0       1               1        0   \n",
              "\n",
              "     Injury  Spiritual_consult  religion_C  ...  occupation_ARTISAN  \\\n",
              "0         0                  1           1  ...                   0   \n",
              "2         0                  1           1  ...                   0   \n",
              "3         0                  1           0  ...                   1   \n",
              "4         0                  1           0  ...                   1   \n",
              "5         0                  1           1  ...                   0   \n",
              "..      ...                ...         ...  ...                 ...   \n",
              "495       0                  1           0  ...                   0   \n",
              "496       0                  0           0  ...                   1   \n",
              "497       0                  1           1  ...                   0   \n",
              "498       0                  0           1  ...                   0   \n",
              "499       0                  1           0  ...                   0   \n",
              "\n",
              "     occupation_C/SERVANT  occupation_FORCE  occupation_RETIRED  \\\n",
              "0                       0                 0                   0   \n",
              "2                       0                 0                   0   \n",
              "3                       0                 0                   0   \n",
              "4                       0                 0                   0   \n",
              "5                       0                 0                   1   \n",
              "..                    ...               ...                 ...   \n",
              "495                     0                 0                   1   \n",
              "496                     0                 0                   0   \n",
              "497                     0                 1                   0   \n",
              "498                     0                 0                   0   \n",
              "499                     0                 0                   0   \n",
              "\n",
              "     occupation_STUDENT  occupation_UNEMPLYD  agecode_1  agecode_2  agecode_3  \\\n",
              "0                     1                    0          1          0          0   \n",
              "2                     1                    0          1          0          0   \n",
              "3                     0                    0          0          1          0   \n",
              "4                     0                    0          1          0          0   \n",
              "5                     0                    0          0          0          1   \n",
              "..                  ...                  ...        ...        ...        ...   \n",
              "495                   0                    0          0          0          1   \n",
              "496                   0                    0          0          1          0   \n",
              "497                   0                    0          0          1          0   \n",
              "498                   1                    0          1          0          0   \n",
              "499                   1                    0          1          0          0   \n",
              "\n",
              "     target  \n",
              "0     01110  \n",
              "2     11101  \n",
              "3     11001  \n",
              "4     11111  \n",
              "5     01100  \n",
              "..      ...  \n",
              "495   10101  \n",
              "496   11011  \n",
              "497   01110  \n",
              "498   01000  \n",
              "499   01100  \n",
              "\n",
              "[484 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db2d6d10-2270-4a19-87c6-b6486aa4ba3b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>faNoily_status</th>\n",
              "      <th>genetic</th>\n",
              "      <th>status</th>\n",
              "      <th>loss_of_parent</th>\n",
              "      <th>divorse</th>\n",
              "      <th>Injury</th>\n",
              "      <th>Spiritual_consult</th>\n",
              "      <th>religion_C</th>\n",
              "      <th>...</th>\n",
              "      <th>occupation_ARTISAN</th>\n",
              "      <th>occupation_C/SERVANT</th>\n",
              "      <th>occupation_FORCE</th>\n",
              "      <th>occupation_RETIRED</th>\n",
              "      <th>occupation_STUDENT</th>\n",
              "      <th>occupation_UNEMPLYD</th>\n",
              "      <th>agecode_1</th>\n",
              "      <th>agecode_2</th>\n",
              "      <th>agecode_3</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>01110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>01100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>0</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>01110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>01000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>01100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>484 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db2d6d10-2270-4a19-87c6-b6486aa4ba3b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db2d6d10-2270-4a19-87c6-b6486aa4ba3b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db2d6d10-2270-4a19-87c6-b6486aa4ba3b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "imbalanced_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "UG4Jdh_vRUV_",
        "outputId": "f43bd2cd-4d7e-4d5e-f3cd-ab28fcbdedad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sex  age  faNoily_status  genetic  status  loss_of_parent  divorse  \\\n",
              "0      1   18               1        1       1               1        0   \n",
              "2      1   22               1        0       1               0        0   \n",
              "3      1   35               0        0       0               0        0   \n",
              "4      1   30               1        1       0               0        0   \n",
              "5      0   86               1        0       0               1        0   \n",
              "..   ...  ...             ...      ...     ...             ...      ...   \n",
              "495    0   73               1        1       1               1        0   \n",
              "496    0   50               0        0       0               1        0   \n",
              "497    0   32               0        0       0               0        0   \n",
              "498    1   13               1        0       1               1        0   \n",
              "499    0   19               1        0       1               1        0   \n",
              "\n",
              "     Injury  Spiritual_consult  Insominia  ...  occupation_ARTISAN  \\\n",
              "0         0                  1          0  ...                   0   \n",
              "2         0                  1          1  ...                   0   \n",
              "3         0                  1          1  ...                   1   \n",
              "4         0                  1          1  ...                   1   \n",
              "5         0                  1          0  ...                   0   \n",
              "..      ...                ...        ...  ...                 ...   \n",
              "495       0                  1          1  ...                   0   \n",
              "496       0                  0          1  ...                   1   \n",
              "497       0                  1          0  ...                   0   \n",
              "498       0                  0          0  ...                   0   \n",
              "499       0                  1          0  ...                   0   \n",
              "\n",
              "     occupation_C/SERVANT  occupation_FORCE  occupation_RETIRED  \\\n",
              "0                       0                 0                   0   \n",
              "2                       0                 0                   0   \n",
              "3                       0                 0                   0   \n",
              "4                       0                 0                   0   \n",
              "5                       0                 0                   1   \n",
              "..                    ...               ...                 ...   \n",
              "495                     0                 0                   1   \n",
              "496                     0                 0                   0   \n",
              "497                     0                 1                   0   \n",
              "498                     0                 0                   0   \n",
              "499                     0                 0                   0   \n",
              "\n",
              "     occupation_STUDENT  occupation_UNEMPLYD  agecode_1  agecode_2  agecode_3  \\\n",
              "0                     1                    0          1          0          0   \n",
              "2                     1                    0          1          0          0   \n",
              "3                     0                    0          0          1          0   \n",
              "4                     0                    0          1          0          0   \n",
              "5                     0                    0          0          0          1   \n",
              "..                  ...                  ...        ...        ...        ...   \n",
              "495                   0                    0          0          0          1   \n",
              "496                   0                    0          0          1          0   \n",
              "497                   0                    0          0          1          0   \n",
              "498                   1                    0          1          0          0   \n",
              "499                   1                    0          1          0          0   \n",
              "\n",
              "     target  \n",
              "0     01110  \n",
              "2     11101  \n",
              "3     11001  \n",
              "4     11111  \n",
              "5     01100  \n",
              "..      ...  \n",
              "495   10101  \n",
              "496   11011  \n",
              "497   01110  \n",
              "498   01000  \n",
              "499   01100  \n",
              "\n",
              "[484 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a714f537-916b-41ae-b00f-db47952db9d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>faNoily_status</th>\n",
              "      <th>genetic</th>\n",
              "      <th>status</th>\n",
              "      <th>loss_of_parent</th>\n",
              "      <th>divorse</th>\n",
              "      <th>Injury</th>\n",
              "      <th>Spiritual_consult</th>\n",
              "      <th>Insominia</th>\n",
              "      <th>...</th>\n",
              "      <th>occupation_ARTISAN</th>\n",
              "      <th>occupation_C/SERVANT</th>\n",
              "      <th>occupation_FORCE</th>\n",
              "      <th>occupation_RETIRED</th>\n",
              "      <th>occupation_STUDENT</th>\n",
              "      <th>occupation_UNEMPLYD</th>\n",
              "      <th>agecode_1</th>\n",
              "      <th>agecode_2</th>\n",
              "      <th>agecode_3</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>01110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>01100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>0</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>01110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>01000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>01100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>484 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a714f537-916b-41ae-b00f-db47952db9d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a714f537-916b-41ae-b00f-db47952db9d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a714f537-916b-41ae-b00f-db47952db9d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "balanced_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phkra0YKsS0S"
      },
      "source": [
        "# Balance dataset with SMOTE\n",
        "Just try SMOTE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "k6xaGUu6R_U0",
        "outputId": "251afe4b-3b80-48bf-fb20-d266917fede1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sex  age  faNoily_status  genetic  status  loss_of_parent  divorse  \\\n",
              "323    0   44               1        1       0               1        0   \n",
              "81     1   41               0        0       0               1        0   \n",
              "186    0   40               0        0       0               0        1   \n",
              "402    0   34               0        0       0               0        0   \n",
              "241    0   24               1        1       1               1        0   \n",
              "..   ...  ...             ...      ...     ...             ...      ...   \n",
              "277    1   43               0        0       0               1        1   \n",
              "309    0   24               1        0       1               0        0   \n",
              "7      1   46               0        1       0               1        0   \n",
              "153    1   43               0        0       0               1        0   \n",
              "230    1   42               0        1       0               0        1   \n",
              "\n",
              "     Injury  Spiritual_consult  shizopherania  ...  religion_O  \\\n",
              "323       0                  1              1  ...           0   \n",
              "81        0                  1              1  ...           0   \n",
              "186       0                  0              1  ...           0   \n",
              "402       0                  0              1  ...           0   \n",
              "241       0                  1              1  ...           1   \n",
              "..      ...                ...            ...  ...         ...   \n",
              "277       1                  1              1  ...           0   \n",
              "309       0                  0              1  ...           0   \n",
              "7         0                  1              1  ...           0   \n",
              "153       0                  0              1  ...           0   \n",
              "230       1                  0              1  ...           0   \n",
              "\n",
              "     occupation_ARTISAN  occupation_C/SERVANT  occupation_FORCE  \\\n",
              "323                   0                     0                 0   \n",
              "81                    0                     0                 0   \n",
              "186                   0                     0                 0   \n",
              "402                   0                     0                 0   \n",
              "241                   0                     0                 0   \n",
              "..                  ...                   ...               ...   \n",
              "277                   0                     1                 0   \n",
              "309                   0                     0                 0   \n",
              "7                     0                     1                 0   \n",
              "153                   0                     0                 0   \n",
              "230                   1                     0                 0   \n",
              "\n",
              "     occupation_RETIRED  occupation_STUDENT  occupation_UNEMPLYD  agecode_1  \\\n",
              "323                   0                   0                    1          0   \n",
              "81                    0                   0                    1          0   \n",
              "186                   0                   0                    1          0   \n",
              "402                   0                   0                    1          0   \n",
              "241                   0                   0                    1          1   \n",
              "..                  ...                 ...                  ...        ...   \n",
              "277                   0                   0                    0          0   \n",
              "309                   0                   1                    0          1   \n",
              "7                     0                   0                    0          0   \n",
              "153                   0                   0                    1          0   \n",
              "230                   0                   0                    0          0   \n",
              "\n",
              "     agecode_2  agecode_3  \n",
              "323          1          0  \n",
              "81           1          0  \n",
              "186          1          0  \n",
              "402          1          0  \n",
              "241          0          0  \n",
              "..         ...        ...  \n",
              "277          1          0  \n",
              "309          0          0  \n",
              "7            1          0  \n",
              "153          1          0  \n",
              "230          1          0  \n",
              "\n",
              "[338 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c236de03-6c14-433a-8b3e-efa3a9887183\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>faNoily_status</th>\n",
              "      <th>genetic</th>\n",
              "      <th>status</th>\n",
              "      <th>loss_of_parent</th>\n",
              "      <th>divorse</th>\n",
              "      <th>Injury</th>\n",
              "      <th>Spiritual_consult</th>\n",
              "      <th>shizopherania</th>\n",
              "      <th>...</th>\n",
              "      <th>religion_O</th>\n",
              "      <th>occupation_ARTISAN</th>\n",
              "      <th>occupation_C/SERVANT</th>\n",
              "      <th>occupation_FORCE</th>\n",
              "      <th>occupation_RETIRED</th>\n",
              "      <th>occupation_STUDENT</th>\n",
              "      <th>occupation_UNEMPLYD</th>\n",
              "      <th>agecode_1</th>\n",
              "      <th>agecode_2</th>\n",
              "      <th>agecode_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309</th>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>338 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c236de03-6c14-433a-8b3e-efa3a9887183')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c236de03-6c14-433a-8b3e-efa3a9887183 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c236de03-6c14-433a-8b3e-efa3a9887183');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "temp = data.copy()\n",
        "y = temp.pop('Insominia')\n",
        "X = temp\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "X_train  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "tTzwXqF8SdNg",
        "outputId": "89d1d651-3545-483d-ccbe-a879215f78eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sex  age  faNoily_status  genetic  status  loss_of_parent  divorse  \\\n",
              "0      0   44               1        1       0               1        0   \n",
              "1      1   41               0        0       0               1        0   \n",
              "2      0   40               0        0       0               0        1   \n",
              "3      0   34               0        0       0               0        0   \n",
              "4      0   24               1        1       1               1        0   \n",
              "..   ...  ...             ...      ...     ...             ...      ...   \n",
              "397    0   60               0        0       0               0        0   \n",
              "398    0   43               1        0       0               0        0   \n",
              "399    0   50               0        1       0               1        0   \n",
              "400    0   67               1        1       0               1        0   \n",
              "401    0   61               0        0       0               0        0   \n",
              "\n",
              "     Injury  Spiritual_consult  shizopherania  ...  religion_O  \\\n",
              "0         0                  1              1  ...           0   \n",
              "1         0                  1              1  ...           0   \n",
              "2         0                  0              1  ...           0   \n",
              "3         0                  0              1  ...           0   \n",
              "4         0                  1              1  ...           1   \n",
              "..      ...                ...            ...  ...         ...   \n",
              "397       0                  1              0  ...           0   \n",
              "398       0                  0              1  ...           0   \n",
              "399       0                  1              1  ...           0   \n",
              "400       0                  1              0  ...           0   \n",
              "401       0                  1              0  ...           0   \n",
              "\n",
              "     occupation_ARTISAN  occupation_C/SERVANT  occupation_FORCE  \\\n",
              "0                     0                     0                 0   \n",
              "1                     0                     0                 0   \n",
              "2                     0                     0                 0   \n",
              "3                     0                     0                 0   \n",
              "4                     0                     0                 0   \n",
              "..                  ...                   ...               ...   \n",
              "397                   0                     0                 0   \n",
              "398                   0                     0                 0   \n",
              "399                   0                     0                 0   \n",
              "400                   0                     0                 0   \n",
              "401                   0                     0                 0   \n",
              "\n",
              "     occupation_RETIRED  occupation_STUDENT  occupation_UNEMPLYD  agecode_1  \\\n",
              "0                     0                   0                    1          0   \n",
              "1                     0                   0                    1          0   \n",
              "2                     0                   0                    1          0   \n",
              "3                     0                   0                    1          0   \n",
              "4                     0                   0                    1          1   \n",
              "..                  ...                 ...                  ...        ...   \n",
              "397                   0                   0                    0          0   \n",
              "398                   0                   0                    1          0   \n",
              "399                   0                   0                    0          0   \n",
              "400                   1                   0                    0          0   \n",
              "401                   1                   0                    0          0   \n",
              "\n",
              "     agecode_2  agecode_3  \n",
              "0            1          0  \n",
              "1            1          0  \n",
              "2            1          0  \n",
              "3            1          0  \n",
              "4            0          0  \n",
              "..         ...        ...  \n",
              "397          0          1  \n",
              "398          1          0  \n",
              "399          0          0  \n",
              "400          0          1  \n",
              "401          0          1  \n",
              "\n",
              "[402 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0e7546a-2dbb-4ef3-9bb5-fe5aa9dc6bb7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>faNoily_status</th>\n",
              "      <th>genetic</th>\n",
              "      <th>status</th>\n",
              "      <th>loss_of_parent</th>\n",
              "      <th>divorse</th>\n",
              "      <th>Injury</th>\n",
              "      <th>Spiritual_consult</th>\n",
              "      <th>shizopherania</th>\n",
              "      <th>...</th>\n",
              "      <th>religion_O</th>\n",
              "      <th>occupation_ARTISAN</th>\n",
              "      <th>occupation_C/SERVANT</th>\n",
              "      <th>occupation_FORCE</th>\n",
              "      <th>occupation_RETIRED</th>\n",
              "      <th>occupation_STUDENT</th>\n",
              "      <th>occupation_UNEMPLYD</th>\n",
              "      <th>agecode_1</th>\n",
              "      <th>agecode_2</th>\n",
              "      <th>agecode_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>0</td>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>402 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0e7546a-2dbb-4ef3-9bb5-fe5aa9dc6bb7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0e7546a-2dbb-4ef3-9bb5-fe5aa9dc6bb7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0e7546a-2dbb-4ef3-9bb5-fe5aa9dc6bb7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# every sample had a total of 101 samples each\n",
        "smote = SMOTE(random_state=101)\n",
        "X_train_balance, y_train_balance = smote.fit_resample(X_train, y_train.ravel())\n",
        "X_train_balance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60xX3SfWceIr"
      },
      "source": [
        "# Multi-Label Classification Model on dataset with class imbalance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fumFpAYshUFS"
      },
      "source": [
        "# Machine learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jN-7jXPMVTGX"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b39OnB92bpK-"
      },
      "source": [
        "Train a Multilayer Perceptron (MLP), Support Vector Machines (SVM), Random Forest (RF) and Decision Tree (DT) on the training data (which is 80% of the whole data). The four algorithms are evaluated on the test set (which is 20% of the sampled data). The accuracy and balanced accuracy are as presented in Table 3.\n",
        "\n",
        "![Table 3.png](data:image/png;base64,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)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "3whzW2UW17n_"
      },
      "outputs": [],
      "source": [
        "ml_results = []\n",
        "dl_results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zY8wh-G3XXtk"
      },
      "outputs": [],
      "source": [
        "temp = imbalanced_data.copy()\n",
        "y_multi_imbalanced = temp.pop('target')\n",
        "X_multi_imbalanced = temp\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_multi_imbalanced, y_multi_imbalanced, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnACvLuiefAV"
      },
      "source": [
        "Multilayer Perceptron (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkzS6vxobomM",
        "outputId": "b38bc403-8d4f-40b0-ee00-f61eb0ad0def"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP for imbalanced data = 0.4536082474226804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "MLP = MLPClassifier()\n",
        "MLP.fit(X_train, y_train)\n",
        "mlp_score = MLP.score(X_test, y_test)\n",
        "ml_results.append(f\"Imbalanced data - MLP: {mlp_score}\")\n",
        "print(f\"MLP for imbalanced data = {mlp_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M74LfhMUeihO"
      },
      "source": [
        "Support Vector Machines (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AST0fEdFeagq",
        "outputId": "1c587d4c-0e36-4acd-db91-711dc87f307c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM for imbalanced data = 0.36082474226804123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "svc = LinearSVC()\n",
        "svc.fit(X_train, y_train)\n",
        "svm_score = svc.score(X_test, y_test)\n",
        "ml_results.append(f\"Imbalanced data - SVM: {svm_score}\")\n",
        "print(f\"SVM for imbalanced data = {svm_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY-WLST_elEu"
      },
      "source": [
        "Random Forest (RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIrOLjSjeobC",
        "outputId": "62d9e327-09d9-441b-8b31-764ea36c750c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF for imbalanced data = 0.41237113402061853\n"
          ]
        }
      ],
      "source": [
        "RF = RandomForestClassifier()\n",
        "RF.fit(X_train, y_train)\n",
        "rf_score = RF.score(X_test, y_test)\n",
        "ml_results.append(f\"Imbalanced data - RF: {rf_score}\")\n",
        "print(f\"RF for imbalanced data = {rf_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDrn5ALEe4Vv"
      },
      "source": [
        "Decision Tree (DT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-rhjK-7e0P4",
        "outputId": "bbdf3bd0-6d21-469d-9291-b3ef1ae399c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DT for imbalanced data = 0.31958762886597936\n"
          ]
        }
      ],
      "source": [
        "decistion_tree = DecisionTreeClassifier()\n",
        "decistion_tree.fit(X_train, y_train)\n",
        "dt_score = decistion_tree.score(X_test, y_test)\n",
        "ml_results.append(f\"Imbalanced data - DT: {dt_score}\")\n",
        "print(f\"DT for imbalanced data = {dt_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtdij27vhZZZ"
      },
      "source": [
        "Deep learning using Neural Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phyKh24iq2hi"
      },
      "source": [
        "Use Neural Network in this paper:\n",
        "https://keras.io/guides/sequential_model/\n",
        "\n",
        "The architectural setup presented in Fig. 4a and b are 3-layer deep fully-connected network with the RELU activation function and architectural layer are 15–20–20-40–1 and 15-20–20-40–5 respectively. The training data is split into a 30% validation set running for 40 epochs with an early stop monitor on validation loss. The optimizer is Adam with a learning rate of 0.01.\n",
        "\n",
        "\n",
        "*   Drop-out is chosen over L1 and L2 regularisation in this study\n",
        "*   Sigmoid and ReLU is the activation function used in this study.\n",
        "*   Optimizer is Adam with a learning rate of 0.01.\n",
        "*   The loss function for training is a binary cross-entropy and evaluation metrics accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9uaf5__u9qky"
      },
      "outputs": [],
      "source": [
        "def MultiLabelNN():\n",
        "  # Create 3 layers\n",
        "  # page 5 - Fig 4.\n",
        "  # found shape=(10, 22)\n",
        "  input = Dense(15, input_dim=22, activation=\"relu\", name=\"Input\")\n",
        "  hidden_layer1 = Dense(20, activation=\"relu\", name=\"layer1\")\n",
        "  hidden_layer2 = Dense(20, activation=\"relu\", name=\"layer2\") \n",
        "  hidden_layer3 = Dense(40, activation=\"relu\", name=\"layer3\") \n",
        "  output = Dense(5, activation=\"sigmoid\", name=\"Output\") \n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(input)\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(hidden_layer1)\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(hidden_layer2)\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(hidden_layer3)\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(output)\n",
        "\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IasS_hfXhdUY",
        "outputId": "a63443d8-2fc6-4464-f784-0fd67a68a90a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "27/27 [==============================] - 2s 4ms/step - loss: 23.8436 - accuracy: 0.3074\n",
            "Epoch 2/40\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1.8502 - accuracy: 0.3037\n",
            "Epoch 3/40\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1.1362 - accuracy: 0.5111\n",
            "Epoch 4/40\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.5593\n",
            "Epoch 5/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7532 - accuracy: 0.5667\n",
            "Epoch 6/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.5407\n",
            "Epoch 7/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.5630\n",
            "Epoch 8/40\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.6381 - accuracy: 0.5630\n",
            "Epoch 9/40\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.7781 - accuracy: 0.5593\n",
            "Epoch 10/40\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.6851 - accuracy: 0.5556\n",
            "Epoch 11/40\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6066 - accuracy: 0.5815\n",
            "Epoch 12/40\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6448 - accuracy: 0.5667\n",
            "Epoch 13/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.5593\n",
            "Epoch 14/40\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.5593\n",
            "Epoch 15/40\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6471 - accuracy: 0.5593\n",
            "Epoch 16/40\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6035 - accuracy: 0.5593\n",
            "Epoch 17/40\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6431 - accuracy: 0.5556\n",
            "Epoch 18/40\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6084 - accuracy: 0.5667\n",
            "Epoch 19/40\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6330 - accuracy: 0.5667\n",
            "Epoch 20/40\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6095 - accuracy: 0.5593\n",
            "Epoch 21/40\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6150 - accuracy: 0.5667\n",
            "Epoch 22/40\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6200 - accuracy: 0.5778\n",
            "Epoch 23/40\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.6134 - accuracy: 0.5630\n",
            "Epoch 24/40\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6016 - accuracy: 0.5556\n",
            "Epoch 25/40\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.6130 - accuracy: 0.5741\n",
            "Epoch 26/40\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.6097 - accuracy: 0.5630\n",
            "Epoch 27/40\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5959 - accuracy: 0.5815\n",
            "Epoch 28/40\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5968 - accuracy: 0.5889\n",
            "Epoch 29/40\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6061 - accuracy: 0.5519\n",
            "Epoch 30/40\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.6097 - accuracy: 0.5926\n",
            "Epoch 31/40\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6090 - accuracy: 0.5556\n",
            "Epoch 32/40\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6009 - accuracy: 0.5667\n",
            "Epoch 33/40\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6089 - accuracy: 0.5667\n",
            "Epoch 34/40\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6219 - accuracy: 0.5704\n",
            "Epoch 35/40\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6072 - accuracy: 0.5630\n",
            "Epoch 36/40\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5952 - accuracy: 0.5667\n",
            "Epoch 37/40\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6092 - accuracy: 0.5741\n",
            "Epoch 38/40\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5995 - accuracy: 0.5630\n",
            "Epoch 39/40\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5935 - accuracy: 0.5741\n",
            "Epoch 40/40\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6047 - accuracy: 0.5778\n",
            "10/10 [==============================] - 1s 5ms/step - loss: 0.5492 - accuracy: 0.6289\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5977 - accuracy: 0.5556\n",
            "Training Loss and Accuracy (test): [0.5492411851882935, 0.6288659572601318]\n",
            "Training Loss and Accuracy (validation): [0.5976652503013611, 0.5555555820465088]\n"
          ]
        }
      ],
      "source": [
        "temp = balanced_data.copy()\n",
        "y_multi_nn = pd.DataFrame([temp.pop(x) for x in ['Insominia', 'shizopherania', 'vascula_demetia', 'MBD', 'Bipolar']]).T\n",
        "\n",
        "X_multi_nn = temp\n",
        "\n",
        "# test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_multi_nn, y_multi_nn, test_size=0.2)\n",
        "\n",
        "# validation\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.3)\n",
        "\n",
        "model = MultiLabelNN()\n",
        "model.fit(\n",
        "    tf.convert_to_tensor(np.asarray(X_train).astype('int')), \n",
        "    tf.convert_to_tensor(y_train),\n",
        "    epochs=40, \n",
        "    batch_size=10\n",
        ")\n",
        "\n",
        "# test\n",
        "test = model.evaluate(tf.convert_to_tensor(np.asarray(X_test).astype('int')), tf.convert_to_tensor(y_test), batch_size=10)\n",
        "\n",
        "# validation\n",
        "validation = model.evaluate(tf.convert_to_tensor(np.asarray(X_validation).astype('int')), tf.convert_to_tensor(y_validation), batch_size=10)\n",
        "\n",
        "print(f'Training Loss and Accuracy (test): {test}')\n",
        "print(f'Training Loss and Accuracy (validation): {validation}')\n",
        "dl_results.append(f\"Imbalanced data - Multi-label NN Loss and Accuracy(test): {test[1]}\")\n",
        "dl_results.append(f\"Imbalanced data - Multi-label NN Loss and Accuracy(validation): {validation[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEvE3sqiqNaU"
      },
      "source": [
        "# Single-Label Classification Model on dataset with class imbalance\n",
        "Using Neural Network with 3-layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "JVfdAtXLinie"
      },
      "outputs": [],
      "source": [
        "def SingleLabelNN():\n",
        "  # Create 3 layers\n",
        "  # page 5 - Fig 4.\n",
        "  # found shape=(10, 25)\n",
        "  input = Dense(15, input_dim=25, activation=\"relu\", name=\"Input\")\n",
        "  hidden_layer1 = Dense(20, activation=\"relu\", name=\"layer1\")\n",
        "  hidden_layer2 = Dense(40, activation=\"relu\", name=\"layer2\") \n",
        "  hidden_layer3 = Dense(50, activation=\"relu\", name=\"layer3\") \n",
        "  output = Dense(1, activation=\"sigmoid\", name=\"Output\") \n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(input)\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(hidden_layer1)\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(hidden_layer2)\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(hidden_layer3)\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(output)\n",
        "\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKafpuATql-b",
        "outputId": "fcf373fd-9962-40d2-f713-2786db5ebf08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "28/28 [==============================] - 1s 4ms/step - loss: 0.8115 - accuracy: 0.5036\n",
            "Epoch 2/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6703 - accuracy: 0.6393\n",
            "Epoch 3/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6150 - accuracy: 0.6786\n",
            "Epoch 4/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6241 - accuracy: 0.6607\n",
            "Epoch 5/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.6929\n",
            "Epoch 6/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7500\n",
            "Epoch 7/40\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.8107\n",
            "Epoch 8/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8500\n",
            "Epoch 9/40\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.8607\n",
            "Epoch 10/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2693 - accuracy: 0.9321\n",
            "Epoch 11/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2581 - accuracy: 0.9321\n",
            "Epoch 12/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3769 - accuracy: 0.8786\n",
            "Epoch 13/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8571\n",
            "Epoch 14/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8500\n",
            "Epoch 15/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2972 - accuracy: 0.9000\n",
            "Epoch 16/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2982 - accuracy: 0.9143\n",
            "Epoch 17/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2137 - accuracy: 0.9464\n",
            "Epoch 18/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2158 - accuracy: 0.9393\n",
            "Epoch 19/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.1995 - accuracy: 0.9429\n",
            "Epoch 20/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2621 - accuracy: 0.9429\n",
            "Epoch 21/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2070 - accuracy: 0.9500\n",
            "Epoch 22/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.9536\n",
            "Epoch 23/40\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.1897 - accuracy: 0.9464\n",
            "Epoch 24/40\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.1387 - accuracy: 0.9714\n",
            "Epoch 25/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.1944 - accuracy: 0.9500\n",
            "Epoch 26/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2680 - accuracy: 0.9143\n",
            "Epoch 27/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2470 - accuracy: 0.9250\n",
            "Epoch 28/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2252 - accuracy: 0.9321\n",
            "Epoch 29/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2797 - accuracy: 0.9321\n",
            "Epoch 30/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8893\n",
            "Epoch 31/40\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.2816 - accuracy: 0.9214\n",
            "Epoch 32/40\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.2541 - accuracy: 0.9250\n",
            "Epoch 33/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2028 - accuracy: 0.9429\n",
            "Epoch 34/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1957 - accuracy: 0.9393\n",
            "Epoch 35/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1793 - accuracy: 0.9464\n",
            "Epoch 36/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.1352 - accuracy: 0.9714\n",
            "Epoch 37/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.1638 - accuracy: 0.9643\n",
            "Epoch 38/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.1737 - accuracy: 0.9536\n",
            "Epoch 39/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2322 - accuracy: 0.9321\n",
            "Epoch 40/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2743 - accuracy: 0.9071\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 1.0000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.9833\n",
            "Epoch 1/40\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.7650 - accuracy: 0.7750\n",
            "Epoch 2/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.8571\n",
            "Epoch 3/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8607\n",
            "Epoch 4/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8643\n",
            "Epoch 5/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8607\n",
            "Epoch 6/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3446 - accuracy: 0.8536\n",
            "Epoch 7/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8571\n",
            "Epoch 8/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3374 - accuracy: 0.8750\n",
            "Epoch 9/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8643\n",
            "Epoch 10/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8750\n",
            "Epoch 11/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3409 - accuracy: 0.8786\n",
            "Epoch 12/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3038 - accuracy: 0.8929\n",
            "Epoch 13/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3341 - accuracy: 0.8857\n",
            "Epoch 14/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2952 - accuracy: 0.9036\n",
            "Epoch 15/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8786\n",
            "Epoch 16/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3147 - accuracy: 0.8857\n",
            "Epoch 17/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2935 - accuracy: 0.8929\n",
            "Epoch 18/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3116 - accuracy: 0.8964\n",
            "Epoch 19/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.8786\n",
            "Epoch 20/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.8857\n",
            "Epoch 21/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2769 - accuracy: 0.9071\n",
            "Epoch 22/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.9143\n",
            "Epoch 23/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2684 - accuracy: 0.9107\n",
            "Epoch 24/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.8750\n",
            "Epoch 25/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3066 - accuracy: 0.8821\n",
            "Epoch 26/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.8893\n",
            "Epoch 27/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.8714\n",
            "Epoch 28/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2640 - accuracy: 0.8893\n",
            "Epoch 29/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2578 - accuracy: 0.8964\n",
            "Epoch 30/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.8750\n",
            "Epoch 31/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2852 - accuracy: 0.9000\n",
            "Epoch 32/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3173 - accuracy: 0.9036\n",
            "Epoch 33/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3076 - accuracy: 0.9000\n",
            "Epoch 34/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2875 - accuracy: 0.9000\n",
            "Epoch 35/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2718 - accuracy: 0.9107\n",
            "Epoch 36/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2999 - accuracy: 0.8821\n",
            "Epoch 37/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2658 - accuracy: 0.9000\n",
            "Epoch 38/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2786 - accuracy: 0.8857\n",
            "Epoch 39/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2515 - accuracy: 0.9036\n",
            "Epoch 40/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2755 - accuracy: 0.9000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.8800\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2630 - accuracy: 0.9083\n",
            "Epoch 1/40\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.9414 - accuracy: 0.5214\n",
            "Epoch 2/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7027 - accuracy: 0.6250\n",
            "Epoch 3/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6591 - accuracy: 0.6464\n",
            "Epoch 4/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.6536\n",
            "Epoch 5/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.6607\n",
            "Epoch 6/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.6536\n",
            "Epoch 7/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.6607\n",
            "Epoch 8/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.6607\n",
            "Epoch 9/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.6607\n",
            "Epoch 10/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6256 - accuracy: 0.6607\n",
            "Epoch 11/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6074 - accuracy: 0.6643\n",
            "Epoch 12/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.6536\n",
            "Epoch 13/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.6643\n",
            "Epoch 14/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5990 - accuracy: 0.6607\n",
            "Epoch 15/40\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.5742 - accuracy: 0.6607\n",
            "Epoch 16/40\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.5877 - accuracy: 0.6643\n",
            "Epoch 17/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5623 - accuracy: 0.6607\n",
            "Epoch 18/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5398 - accuracy: 0.6571\n",
            "Epoch 19/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6412 - accuracy: 0.6571\n",
            "Epoch 20/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5892 - accuracy: 0.6643\n",
            "Epoch 21/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6117 - accuracy: 0.6607\n",
            "Epoch 22/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5707 - accuracy: 0.6607\n",
            "Epoch 23/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5848 - accuracy: 0.6607\n",
            "Epoch 24/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5880 - accuracy: 0.6607\n",
            "Epoch 25/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5761 - accuracy: 0.6607\n",
            "Epoch 26/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6015 - accuracy: 0.6607\n",
            "Epoch 27/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5941 - accuracy: 0.6607\n",
            "Epoch 28/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5899 - accuracy: 0.6607\n",
            "Epoch 29/40\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.5570 - accuracy: 0.6607\n",
            "Epoch 30/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5833 - accuracy: 0.6607\n",
            "Epoch 31/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5438 - accuracy: 0.6607\n",
            "Epoch 32/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5703 - accuracy: 0.6607\n",
            "Epoch 33/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5817 - accuracy: 0.6607\n",
            "Epoch 34/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.6607\n",
            "Epoch 35/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.6607\n",
            "Epoch 36/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5727 - accuracy: 0.6607\n",
            "Epoch 37/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.6607\n",
            "Epoch 38/40\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.5742 - accuracy: 0.6607\n",
            "Epoch 39/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5523 - accuracy: 0.6607\n",
            "Epoch 40/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5503 - accuracy: 0.6607\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.5806 - accuracy: 0.6700\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7833\n",
            "Epoch 1/40\n",
            "28/28 [==============================] - 1s 4ms/step - loss: 1.2127 - accuracy: 0.4464\n",
            "Epoch 2/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.5536\n",
            "Epoch 3/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7129 - accuracy: 0.5179\n",
            "Epoch 4/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6856 - accuracy: 0.5071\n",
            "Epoch 5/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6875 - accuracy: 0.5536\n",
            "Epoch 6/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6696 - accuracy: 0.5750\n",
            "Epoch 7/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 0.5357\n",
            "Epoch 8/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.5643\n",
            "Epoch 9/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.5643\n",
            "Epoch 10/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.5750\n",
            "Epoch 11/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6588 - accuracy: 0.5893\n",
            "Epoch 12/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.5786\n",
            "Epoch 13/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.5679\n",
            "Epoch 14/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 0.6107\n",
            "Epoch 15/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.5857\n",
            "Epoch 16/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.5929\n",
            "Epoch 17/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.6071\n",
            "Epoch 18/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.6214\n",
            "Epoch 19/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6578 - accuracy: 0.6107\n",
            "Epoch 20/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6405 - accuracy: 0.6214\n",
            "Epoch 21/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.6107\n",
            "Epoch 22/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.6500\n",
            "Epoch 23/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.6143\n",
            "Epoch 24/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.6286\n",
            "Epoch 25/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6186 - accuracy: 0.6607\n",
            "Epoch 26/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.6143\n",
            "Epoch 27/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.6143\n",
            "Epoch 28/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.6429\n",
            "Epoch 29/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.5929\n",
            "Epoch 30/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.5857\n",
            "Epoch 31/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.5929\n",
            "Epoch 32/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.6464\n",
            "Epoch 33/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.6536\n",
            "Epoch 34/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6064 - accuracy: 0.6393\n",
            "Epoch 35/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6240 - accuracy: 0.6500\n",
            "Epoch 36/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6153 - accuracy: 0.6286\n",
            "Epoch 37/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.5929\n",
            "Epoch 38/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.6214\n",
            "Epoch 39/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6194 - accuracy: 0.6250\n",
            "Epoch 40/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.5679\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.5700\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.6083\n",
            "Epoch 1/40\n",
            "28/28 [==============================] - 1s 4ms/step - loss: 0.9384 - accuracy: 0.5607\n",
            "Epoch 2/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.5964\n",
            "Epoch 3/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6542 - accuracy: 0.6500\n",
            "Epoch 4/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.6857\n",
            "Epoch 5/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.6964\n",
            "Epoch 6/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7536\n",
            "Epoch 7/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.8321\n",
            "Epoch 8/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4972 - accuracy: 0.7857\n",
            "Epoch 9/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.8607\n",
            "Epoch 10/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3504 - accuracy: 0.8750\n",
            "Epoch 11/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3373 - accuracy: 0.8750\n",
            "Epoch 12/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3594 - accuracy: 0.8607\n",
            "Epoch 13/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2973 - accuracy: 0.8857\n",
            "Epoch 14/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3063 - accuracy: 0.8679\n",
            "Epoch 15/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2888 - accuracy: 0.8964\n",
            "Epoch 16/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2786 - accuracy: 0.8786\n",
            "Epoch 17/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2267 - accuracy: 0.8964\n",
            "Epoch 18/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2240 - accuracy: 0.8964\n",
            "Epoch 19/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2552 - accuracy: 0.8679\n",
            "Epoch 20/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2544 - accuracy: 0.8821\n",
            "Epoch 21/40\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.2519 - accuracy: 0.8821\n",
            "Epoch 22/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2045 - accuracy: 0.9000\n",
            "Epoch 23/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2147 - accuracy: 0.8821\n",
            "Epoch 24/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3035 - accuracy: 0.8750\n",
            "Epoch 25/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2940 - accuracy: 0.9143\n",
            "Epoch 26/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.4796 - accuracy: 0.8071\n",
            "Epoch 27/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8643\n",
            "Epoch 28/40\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.3502 - accuracy: 0.8821\n",
            "Epoch 29/40\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.2997 - accuracy: 0.9000\n",
            "Epoch 30/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2856 - accuracy: 0.9071\n",
            "Epoch 31/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2815 - accuracy: 0.9107\n",
            "Epoch 32/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8714\n",
            "Epoch 33/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2846 - accuracy: 0.9000\n",
            "Epoch 34/40\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.3599 - accuracy: 0.8714\n",
            "Epoch 35/40\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.3306 - accuracy: 0.8821\n",
            "Epoch 36/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.8714\n",
            "Epoch 37/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3386 - accuracy: 0.8821\n",
            "Epoch 38/40\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.2785 - accuracy: 0.9107\n",
            "Epoch 39/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3624 - accuracy: 0.8679\n",
            "Epoch 40/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3186 - accuracy: 0.8893\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2034 - accuracy: 0.9900\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1423 - accuracy: 0.9750\n",
            "Insominia - Training Loss and Accuracy (test): [0.09288005530834198, 1.0]\n",
            "Insominia - Training Loss and Accuracy (validation): [0.12525580823421478, 0.9833333492279053]\n",
            "shizopherania - Training Loss and Accuracy (test): [0.455827534198761, 0.8799999952316284]\n",
            "shizopherania - Training Loss and Accuracy (validation): [0.26298126578330994, 0.9083333611488342]\n",
            "vascula_demetia - Training Loss and Accuracy (test): [0.5806031823158264, 0.6700000166893005]\n",
            "vascula_demetia - Training Loss and Accuracy (validation): [0.4583800137042999, 0.7833333611488342]\n",
            "MBD - Training Loss and Accuracy (test): [0.6539689898490906, 0.5699999928474426]\n",
            "MBD - Training Loss and Accuracy (validation): [0.6293355822563171, 0.6083333492279053]\n",
            "Bipolar - Training Loss and Accuracy (test): [0.20344658195972443, 0.9900000095367432]\n",
            "Bipolar - Training Loss and Accuracy (validation): [0.14232613146305084, 0.9750000238418579]\n"
          ]
        }
      ],
      "source": [
        "diseases = ['Insominia', 'shizopherania', 'vascula_demetia', 'MBD', 'Bipolar']\n",
        "\n",
        "losses = []\n",
        "\n",
        "for d in diseases:\n",
        "  X = data_original.copy()\n",
        "  y = X.pop(d)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "  X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.3)\n",
        "\n",
        "  model = SingleLabelNN()\n",
        "  model.fit(\n",
        "      tf.convert_to_tensor(np.asarray(X_train).astype('int')), \n",
        "      tf.convert_to_tensor(y_train),\n",
        "      epochs=40, \n",
        "      batch_size=10\n",
        "  )\n",
        "\n",
        "  # test\n",
        "  test = model.evaluate(tf.convert_to_tensor(np.asarray(X_test).astype('int')), tf.convert_to_tensor(y_test), batch_size=10)\n",
        "\n",
        "  # validation\n",
        "  validation = model.evaluate(tf.convert_to_tensor(np.asarray(X_validation).astype('int')), tf.convert_to_tensor(y_validation), batch_size=10)\n",
        "\n",
        "  losses.append(f'{d} - Training Loss and Accuracy (test): {test}')\n",
        "  losses.append(f'{d} - Training Loss and Accuracy (validation): {validation}')\n",
        "  dl_results.append(f\"Imbalanced data - Single-label {d} NN Loss and Accuracy(test): {test[1]}\")\n",
        "  dl_results.append(f\"Imbalanced data - Single-label {d} NN Loss and Accuracy(validation): {validation[1]}\")\n",
        "\n",
        "for l in losses:\n",
        "  print(l)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKFRCiovfFto"
      },
      "source": [
        "# Multi-Label Classification Model on dataset without class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "bMf0-VLkfNTs"
      },
      "outputs": [],
      "source": [
        "temp = imbalanced_data.copy()\n",
        "y_balanced = temp.pop('target')\n",
        "X_balanced = temp\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2)\n",
        "\n",
        "# balance data using SMOTE\n",
        "# We then apply SMOTE on the data, such that every sample had a total of 101 samples each\n",
        "smote = SMOTE(random_state=101)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train.ravel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4-pDWMyfNTs"
      },
      "source": [
        "Multilayer Perceptron (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pIEXwPVgHvN",
        "outputId": "85881537-357c-4608-c9ea-f55381568e1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP for balanced data = 0.36082474226804123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "MLP = MLPClassifier()\n",
        "MLP.fit(X_train_balanced, y_train_balanced)\n",
        "mlp_score = MLP.score(X_test, y_test)\n",
        "ml_results.append(f\"Balanced data - MLP: {mlp_score}\")\n",
        "print(f\"MLP for balanced data = {mlp_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1SSfz4GfNTt"
      },
      "source": [
        "Support Vector Machines (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMgTnliHfNTt",
        "outputId": "5f3f4cdb-01f0-4904-acea-21b3bfd67011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM for balanced data = 0.32989690721649484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "svc = LinearSVC()\n",
        "svc.fit(X_train_balanced, y_train_balanced)\n",
        "svm_score = svc.score(X_test, y_test)\n",
        "ml_results.append(f\"Balanced data - SVM: {svm_score}\")\n",
        "print(f\"SVM for balanced data = {svm_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsQ7NONdfNTt"
      },
      "source": [
        "Random Forest (RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrZH6PGRfNTt",
        "outputId": "293436f1-f4f2-4b5b-ca46-3bc73a84b686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF for balanced data = 0.36082474226804123\n"
          ]
        }
      ],
      "source": [
        "RF = RandomForestClassifier()\n",
        "RF.fit(X_train_balanced, y_train_balanced)\n",
        "rf_score = RF.score(X_test, y_test)\n",
        "ml_results.append(f\"Balanced data - RF: {rf_score}\")\n",
        "print(f\"RF for balanced data = {rf_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzzRhgWUfNTt"
      },
      "source": [
        "Decision Tree (DT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaSVW55mfNTt",
        "outputId": "e2490759-df0f-4d8c-ad26-73997b2967e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DT for balanced data = 0.26804123711340205\n"
          ]
        }
      ],
      "source": [
        "decistion_tree = DecisionTreeClassifier()\n",
        "decistion_tree.fit(X_train_balanced, y_train_balanced)\n",
        "dt_score = decistion_tree.score(X_test, y_test)\n",
        "ml_results.append(f\"Balanced data - DT: {dt_score}\")\n",
        "print(f\"DT for balanced data = {dt_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VubU39Cnj5Sw"
      },
      "source": [
        "Deep learning using Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "p4GnqmMpkBik"
      },
      "outputs": [],
      "source": [
        "def MultiLabelNN():\n",
        "  # Create 3 layers\n",
        "  # page 5 - Fig 4.\n",
        "  # found shape=(None, 21)\n",
        "  input = Dense(15, input_dim=21, activation=\"relu\", name=\"Input\")\n",
        "  hidden_layer1 = Dense(20, activation=\"relu\", name=\"layer1\")\n",
        "  hidden_layer2 = Dense(20, activation=\"relu\", name=\"layer2\") \n",
        "  hidden_layer3 = Dense(40, activation=\"relu\", name=\"layer3\") \n",
        "  output = Dense(5, activation=\"sigmoid\", name=\"Output\") \n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(input)\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(hidden_layer1)\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(hidden_layer2)\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(hidden_layer3)\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(output)\n",
        "\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVEx0iU2khLM",
        "outputId": "21a79fd7-f949-48c5-f802-aa7e939dd024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "68/68 [==============================] - 2s 3ms/step - loss: 0.6982 - accuracy: 0.3850\n",
            "Epoch 2/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.6182 - accuracy: 0.4351\n",
            "Epoch 3/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.4410\n",
            "Epoch 4/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.4690\n",
            "Epoch 5/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5827 - accuracy: 0.4248\n",
            "Epoch 6/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.4882\n",
            "Epoch 7/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.4749\n",
            "Epoch 8/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.4823\n",
            "Epoch 9/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5559 - accuracy: 0.4602\n",
            "Epoch 10/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5451 - accuracy: 0.4720\n",
            "Epoch 11/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.4631\n",
            "Epoch 12/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.4764\n",
            "Epoch 13/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.5133\n",
            "Epoch 14/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.4661\n",
            "Epoch 15/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5567 - accuracy: 0.4395\n",
            "Epoch 16/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.4513\n",
            "Epoch 17/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5546 - accuracy: 0.4926\n",
            "Epoch 18/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.5147\n",
            "Epoch 19/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.4897\n",
            "Epoch 20/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.4454\n",
            "Epoch 21/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5496 - accuracy: 0.4115\n",
            "Epoch 22/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.4985\n",
            "Epoch 23/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5546 - accuracy: 0.4705\n",
            "Epoch 24/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.4410\n",
            "Epoch 25/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.4661\n",
            "Epoch 26/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.4513\n",
            "Epoch 27/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.4528\n",
            "Epoch 28/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.4454\n",
            "Epoch 29/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.4558\n",
            "Epoch 30/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.4484\n",
            "Epoch 31/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5397 - accuracy: 0.4631\n",
            "Epoch 32/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.4071\n",
            "Epoch 33/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.4381\n",
            "Epoch 34/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.4602\n",
            "Epoch 35/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5417 - accuracy: 0.4602\n",
            "Epoch 36/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.4794\n",
            "Epoch 37/40\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.4440\n",
            "Epoch 38/40\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.5306 - accuracy: 0.4322\n",
            "Epoch 39/40\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.5285 - accuracy: 0.4572\n",
            "Epoch 40/40\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.5263 - accuracy: 0.4484\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.5144\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.5533\n",
            "Training Loss and Accuracy (test): [0.5158270597457886, 0.5144032835960388]\n",
            "Training Loss and Accuracy (validation): [0.551461935043335, 0.5532646179199219]\n"
          ]
        }
      ],
      "source": [
        "temp = imbalanced_data.copy()\n",
        "y = temp.pop('target')\n",
        "X = temp\n",
        "\n",
        "X_balanced_new, y_balanced_new = smote.fit_resample(X, y.ravel())\n",
        "\n",
        "# Re-split the target column back into 5 diseases columns. \n",
        "separated_diseases = []\n",
        "for value in y_balanced_new.ravel():\n",
        "  item = []\n",
        "  for v in value:\n",
        "    item.append(v)\n",
        "  separated_diseases.append(item)\n",
        "\n",
        "y = pd.DataFrame(separated_diseases, columns = ['Insominia', 'shizopherania', 'vascula_demetia', 'MBD', 'Bipolar']).astype('int')\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_balanced_new, y, test_size=0.2)\n",
        "\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.3)\n",
        "\n",
        "model = MultiLabelNN()\n",
        "model.fit(\n",
        "    tf.convert_to_tensor(np.asarray(X_train).astype('int')), \n",
        "    tf.convert_to_tensor(y_train),\n",
        "    epochs=40, \n",
        "    batch_size=10\n",
        ")\n",
        "\n",
        "# test\n",
        "test = model.evaluate(tf.convert_to_tensor(np.asarray(X_test).astype('int')), tf.convert_to_tensor(y_test), batch_size=10)\n",
        "\n",
        "# validation\n",
        "validation = model.evaluate(tf.convert_to_tensor(np.asarray(X_validation).astype('int')), tf.convert_to_tensor(y_validation), batch_size=10)\n",
        "\n",
        "print(f'Training Loss and Accuracy (test): {test}')\n",
        "print(f'Training Loss and Accuracy (validation): {validation}')\n",
        "\n",
        "dl_results.append(f\"Balanced data - Multi-label NN Loss and Accuracy(test): {test[1]}\")\n",
        "dl_results.append(f\"Balanced data - Multi-label NN Loss and Accuracy(validation): {validation[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk1DeGwPqiXr"
      },
      "source": [
        "# Single-Label Classification Model on dataset without class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "PANO53M4kPtI"
      },
      "outputs": [],
      "source": [
        "def SingleLabelNN():\n",
        "  # Create 3 layers\n",
        "  # page 5 - Fig 4.\n",
        "  # found shape=(None, 25)\n",
        "  input = Dense(15, input_dim=25, activation=\"relu\", name=\"Input\")\n",
        "  hidden_layer1 = Dense(20, activation=\"relu\", name=\"layer1\")\n",
        "  hidden_layer2 = Dense(40, activation=\"relu\", name=\"layer2\") \n",
        "  hidden_layer3 = Dense(50, activation=\"relu\", name=\"layer3\") \n",
        "  output = Dense(1, activation=\"sigmoid\", name=\"Output\") \n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(input)\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(hidden_layer1)\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(hidden_layer2)\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(hidden_layer3)\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(output)\n",
        "\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqQkD_ouHqS3",
        "outputId": "1a4ab9b3-e0f4-4b14-c0cd-28856e141ad9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "33/33 [==============================] - 2s 5ms/step - loss: 1.2493 - accuracy: 0.5309\n",
            "Epoch 2/40\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6719 - accuracy: 0.6142\n",
            "Epoch 3/40\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6684 - accuracy: 0.6204\n",
            "Epoch 4/40\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5976 - accuracy: 0.6914\n",
            "Epoch 5/40\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5849 - accuracy: 0.6944\n",
            "Epoch 6/40\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5104 - accuracy: 0.7284\n",
            "Epoch 7/40\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5384 - accuracy: 0.7130\n",
            "Epoch 8/40\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.8179\n",
            "Epoch 9/40\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3111 - accuracy: 0.8827\n",
            "Epoch 10/40\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2390 - accuracy: 0.9105\n",
            "Epoch 11/40\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2329 - accuracy: 0.9290\n",
            "Epoch 12/40\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.1675 - accuracy: 0.9537\n",
            "Epoch 13/40\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2308 - accuracy: 0.9259\n",
            "Epoch 14/40\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2931 - accuracy: 0.8549\n",
            "Epoch 15/40\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3076 - accuracy: 0.8704\n",
            "Epoch 16/40\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2678 - accuracy: 0.8951\n",
            "Epoch 17/40\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.1571 - accuracy: 0.9321\n",
            "Epoch 18/40\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2091 - accuracy: 0.8981\n",
            "Epoch 19/40\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.1360 - accuracy: 0.9414\n",
            "Epoch 20/40\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.1485 - accuracy: 0.9660\n",
            "Epoch 21/40\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.1183 - accuracy: 0.9537\n",
            "Epoch 22/40\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1086 - accuracy: 0.9568\n",
            "Epoch 23/40\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 0.9660\n",
            "Epoch 24/40\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0538 - accuracy: 0.9877\n",
            "Epoch 25/40\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0888 - accuracy: 0.9722\n",
            "Epoch 26/40\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.0497 - accuracy: 0.9907\n",
            "Epoch 27/40\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0631 - accuracy: 0.9846\n",
            "Epoch 28/40\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0704 - accuracy: 0.9784\n",
            "Epoch 29/40\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0522 - accuracy: 0.9846\n",
            "Epoch 30/40\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9753\n",
            "Epoch 31/40\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0976 - accuracy: 0.9722\n",
            "Epoch 32/40\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.9846\n",
            "Epoch 33/40\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 0.9846\n",
            "Epoch 34/40\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 0.9938\n",
            "Epoch 35/40\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9877\n",
            "Epoch 36/40\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9846\n",
            "Epoch 37/40\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9846\n",
            "Epoch 38/40\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9907\n",
            "Epoch 39/40\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9877\n",
            "Epoch 40/40\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9907\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.5150e-06 - accuracy: 1.0000\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 1.6993e-06 - accuracy: 1.0000\n",
            "Epoch 1/40\n",
            "48/48 [==============================] - 2s 3ms/step - loss: 1.1713 - accuracy: 0.5802\n",
            "Epoch 2/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.7806\n",
            "Epoch 3/40\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3424 - accuracy: 0.8671\n",
            "Epoch 4/40\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3352 - accuracy: 0.8692\n",
            "Epoch 5/40\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2394 - accuracy: 0.9177\n",
            "Epoch 6/40\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.2255 - accuracy: 0.9283\n",
            "Epoch 7/40\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2396 - accuracy: 0.9008\n",
            "Epoch 8/40\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2408 - accuracy: 0.9283\n",
            "Epoch 9/40\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1952 - accuracy: 0.9473\n",
            "Epoch 10/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2396 - accuracy: 0.9409\n",
            "Epoch 11/40\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1975 - accuracy: 0.9325\n",
            "Epoch 12/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.2074 - accuracy: 0.9346\n",
            "Epoch 13/40\n",
            "48/48 [==============================] - 0s 9ms/step - loss: 0.1991 - accuracy: 0.9494\n",
            "Epoch 14/40\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.2248 - accuracy: 0.9283\n",
            "Epoch 15/40\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.1981 - accuracy: 0.9388\n",
            "Epoch 16/40\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1548 - accuracy: 0.9578\n",
            "Epoch 17/40\n",
            "48/48 [==============================] - 1s 14ms/step - loss: 0.1598 - accuracy: 0.9515\n",
            "Epoch 18/40\n",
            "48/48 [==============================] - 1s 11ms/step - loss: 0.1538 - accuracy: 0.9515\n",
            "Epoch 19/40\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.2222 - accuracy: 0.9241\n",
            "Epoch 20/40\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.1901 - accuracy: 0.9388\n",
            "Epoch 21/40\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.1912 - accuracy: 0.9283\n",
            "Epoch 22/40\n",
            "48/48 [==============================] - 1s 13ms/step - loss: 0.1379 - accuracy: 0.9494\n",
            "Epoch 23/40\n",
            "48/48 [==============================] - 1s 10ms/step - loss: 0.1835 - accuracy: 0.9325\n",
            "Epoch 24/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.1731 - accuracy: 0.9430\n",
            "Epoch 25/40\n",
            "48/48 [==============================] - 0s 8ms/step - loss: 0.1693 - accuracy: 0.9515\n",
            "Epoch 26/40\n",
            "48/48 [==============================] - 1s 18ms/step - loss: 0.1272 - accuracy: 0.9515\n",
            "Epoch 27/40\n",
            "48/48 [==============================] - 1s 15ms/step - loss: 0.2092 - accuracy: 0.9325\n",
            "Epoch 28/40\n",
            "48/48 [==============================] - 1s 12ms/step - loss: 0.1485 - accuracy: 0.9430\n",
            "Epoch 29/40\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.1443 - accuracy: 0.9515\n",
            "Epoch 30/40\n",
            "48/48 [==============================] - 0s 8ms/step - loss: 0.1201 - accuracy: 0.9557\n",
            "Epoch 31/40\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1598 - accuracy: 0.9578\n",
            "Epoch 32/40\n",
            "48/48 [==============================] - 0s 9ms/step - loss: 0.1651 - accuracy: 0.9578\n",
            "Epoch 33/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.1994 - accuracy: 0.9388\n",
            "Epoch 34/40\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.1339 - accuracy: 0.9451\n",
            "Epoch 35/40\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1708 - accuracy: 0.9515\n",
            "Epoch 36/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.1234 - accuracy: 0.9515\n",
            "Epoch 37/40\n",
            "48/48 [==============================] - 0s 8ms/step - loss: 0.1548 - accuracy: 0.9494\n",
            "Epoch 38/40\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.1692 - accuracy: 0.9451\n",
            "Epoch 39/40\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.1399 - accuracy: 0.9641\n",
            "Epoch 40/40\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.1606 - accuracy: 0.9367\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2856 - accuracy: 0.9175\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 0.1829 - accuracy: 0.9505\n",
            "Epoch 1/40\n",
            "38/38 [==============================] - 2s 4ms/step - loss: 0.9896 - accuracy: 0.5294\n",
            "Epoch 2/40\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.7214 - accuracy: 0.5053\n",
            "Epoch 3/40\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6898 - accuracy: 0.5695\n",
            "Epoch 4/40\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6914 - accuracy: 0.5428\n",
            "Epoch 5/40\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6712 - accuracy: 0.6230\n",
            "Epoch 6/40\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6342 - accuracy: 0.6578\n",
            "Epoch 7/40\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.6147 - accuracy: 0.6818\n",
            "Epoch 8/40\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.5666 - accuracy: 0.7513\n",
            "Epoch 9/40\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5135 - accuracy: 0.7834\n",
            "Epoch 10/40\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6113 - accuracy: 0.6925\n",
            "Epoch 11/40\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5344 - accuracy: 0.7513\n",
            "Epoch 12/40\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.5831 - accuracy: 0.6979\n",
            "Epoch 13/40\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5624 - accuracy: 0.7433\n",
            "Epoch 14/40\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.4757 - accuracy: 0.8021\n",
            "Epoch 15/40\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.4822 - accuracy: 0.8128\n",
            "Epoch 16/40\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4746 - accuracy: 0.7968\n",
            "Epoch 17/40\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.5110 - accuracy: 0.7674\n",
            "Epoch 18/40\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4872 - accuracy: 0.7914\n",
            "Epoch 19/40\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.8209\n",
            "Epoch 20/40\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.4351 - accuracy: 0.8155\n",
            "Epoch 21/40\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.5924 - accuracy: 0.6390\n",
            "Epoch 22/40\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4784 - accuracy: 0.7995\n",
            "Epoch 23/40\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.4453 - accuracy: 0.8262\n",
            "Epoch 24/40\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.8048\n",
            "Epoch 25/40\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.5154 - accuracy: 0.7807\n",
            "Epoch 26/40\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.4878 - accuracy: 0.8075\n",
            "Epoch 27/40\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.4444 - accuracy: 0.8262\n",
            "Epoch 28/40\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.5383 - accuracy: 0.7513\n",
            "Epoch 29/40\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7754\n",
            "Epoch 30/40\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.8235\n",
            "Epoch 31/40\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.4743 - accuracy: 0.8182\n",
            "Epoch 32/40\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.8316\n",
            "Epoch 33/40\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.4753 - accuracy: 0.7995\n",
            "Epoch 34/40\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.4903 - accuracy: 0.8021\n",
            "Epoch 35/40\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.5156 - accuracy: 0.7834\n",
            "Epoch 36/40\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.8048\n",
            "Epoch 37/40\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.5286 - accuracy: 0.7914\n",
            "Epoch 38/40\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.8369\n",
            "Epoch 39/40\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4752 - accuracy: 0.8048\n",
            "Epoch 40/40\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.8342\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5032 - accuracy: 0.7938\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.8101\n",
            "Epoch 1/40\n",
            "29/29 [==============================] - 2s 3ms/step - loss: 0.9529 - accuracy: 0.4366\n",
            "Epoch 2/40\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6948 - accuracy: 0.4859\n",
            "Epoch 3/40\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6630 - accuracy: 0.5493\n",
            "Epoch 4/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6870 - accuracy: 0.5528\n",
            "Epoch 5/40\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.6656 - accuracy: 0.5880\n",
            "Epoch 6/40\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.6595 - accuracy: 0.6092\n",
            "Epoch 7/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6664 - accuracy: 0.5775\n",
            "Epoch 8/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6601 - accuracy: 0.5775\n",
            "Epoch 9/40\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.6547 - accuracy: 0.6092\n",
            "Epoch 10/40\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.6554 - accuracy: 0.5951\n",
            "Epoch 11/40\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.6573 - accuracy: 0.6162\n",
            "Epoch 12/40\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.6479 - accuracy: 0.6232\n",
            "Epoch 13/40\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.6586 - accuracy: 0.6021\n",
            "Epoch 14/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6476 - accuracy: 0.6127\n",
            "Epoch 15/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6430 - accuracy: 0.6092\n",
            "Epoch 16/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6480 - accuracy: 0.6444\n",
            "Epoch 17/40\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.6515 - accuracy: 0.6620\n",
            "Epoch 18/40\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.6446 - accuracy: 0.6373\n",
            "Epoch 19/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6318 - accuracy: 0.6197\n",
            "Epoch 20/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6177 - accuracy: 0.6373\n",
            "Epoch 21/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6347 - accuracy: 0.6444\n",
            "Epoch 22/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6331 - accuracy: 0.6585\n",
            "Epoch 23/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6049 - accuracy: 0.6444\n",
            "Epoch 24/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6770 - accuracy: 0.5845\n",
            "Epoch 25/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6832 - accuracy: 0.5845\n",
            "Epoch 26/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6230 - accuracy: 0.6479\n",
            "Epoch 27/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6523 - accuracy: 0.6549\n",
            "Epoch 28/40\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.6337 - accuracy: 0.6373\n",
            "Epoch 29/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6064 - accuracy: 0.6620\n",
            "Epoch 30/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6155 - accuracy: 0.6514\n",
            "Epoch 31/40\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.5996 - accuracy: 0.7113\n",
            "Epoch 32/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.5997 - accuracy: 0.6831\n",
            "Epoch 33/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6113 - accuracy: 0.6725\n",
            "Epoch 34/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.5960 - accuracy: 0.7042\n",
            "Epoch 35/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6041 - accuracy: 0.6761\n",
            "Epoch 36/40\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.6307 - accuracy: 0.6479\n",
            "Epoch 37/40\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6282 - accuracy: 0.6690\n",
            "Epoch 38/40\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.6585\n",
            "Epoch 39/40\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6789 - accuracy: 0.5810\n",
            "Epoch 40/40\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.5986\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6068 - accuracy: 0.6701\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.6282\n",
            "Epoch 1/40\n",
            "34/34 [==============================] - 2s 3ms/step - loss: 1.0584 - accuracy: 0.5482\n",
            "Epoch 2/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6972 - accuracy: 0.5422\n",
            "Epoch 3/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6702 - accuracy: 0.5843\n",
            "Epoch 4/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.5964\n",
            "Epoch 5/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.5964\n",
            "Epoch 6/40\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.6928\n",
            "Epoch 7/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.7500\n",
            "Epoch 8/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.8102\n",
            "Epoch 9/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2327 - accuracy: 0.9187\n",
            "Epoch 10/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.3569 - accuracy: 0.8645\n",
            "Epoch 11/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1440 - accuracy: 0.9578\n",
            "Epoch 12/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.0882 - accuracy: 0.9759\n",
            "Epoch 13/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1496 - accuracy: 0.9639\n",
            "Epoch 14/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2980 - accuracy: 0.8313\n",
            "Epoch 15/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2084 - accuracy: 0.8645\n",
            "Epoch 16/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1075 - accuracy: 0.9639\n",
            "Epoch 17/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1120 - accuracy: 0.9639\n",
            "Epoch 18/40\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1038 - accuracy: 0.9548\n",
            "Epoch 19/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9488\n",
            "Epoch 20/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1809 - accuracy: 0.9488\n",
            "Epoch 21/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1748 - accuracy: 0.9428\n",
            "Epoch 22/40\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1560 - accuracy: 0.9548\n",
            "Epoch 23/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1126 - accuracy: 0.9608\n",
            "Epoch 24/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1040 - accuracy: 0.9608\n",
            "Epoch 25/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.0918 - accuracy: 0.9699\n",
            "Epoch 26/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1272 - accuracy: 0.9428\n",
            "Epoch 27/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9488\n",
            "Epoch 28/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1290 - accuracy: 0.9428\n",
            "Epoch 29/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.0790 - accuracy: 0.9699\n",
            "Epoch 30/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.0937 - accuracy: 0.9639\n",
            "Epoch 31/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.0867 - accuracy: 0.9729\n",
            "Epoch 32/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1377 - accuracy: 0.9548\n",
            "Epoch 33/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.0834 - accuracy: 0.9729\n",
            "Epoch 34/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1083 - accuracy: 0.9578\n",
            "Epoch 35/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1091 - accuracy: 0.9608\n",
            "Epoch 36/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.9849\n",
            "Epoch 37/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.0977 - accuracy: 0.9699\n",
            "Epoch 38/40\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9578\n",
            "Epoch 39/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.2027 - accuracy: 0.9127\n",
            "Epoch 40/40\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 0.1823 - accuracy: 0.9157\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Insominia - Training Loss and Accuracy (test): [4.515011823968962e-06, 1.0]\n",
            "Insominia - Training Loss and Accuracy (validation): [1.6993163853840088e-06, 1.0]\n",
            "shizopherania - Training Loss and Accuracy (test): [0.2855691909790039, 0.9175257682800293]\n",
            "shizopherania - Training Loss and Accuracy (validation): [0.18287979066371918, 0.9504950642585754]\n",
            "vascula_demetia - Training Loss and Accuracy (test): [0.5031750202178955, 0.7938144207000732]\n",
            "vascula_demetia - Training Loss and Accuracy (validation): [0.4653048515319824, 0.8101266026496887]\n",
            "MBD - Training Loss and Accuracy (test): [0.6068398952484131, 0.6701030731201172]\n",
            "MBD - Training Loss and Accuracy (validation): [0.6368270516395569, 0.6282051205635071]\n",
            "Bipolar - Training Loss and Accuracy (test): [0.0027929390780627728, 1.0]\n",
            "Bipolar - Training Loss and Accuracy (validation): [0.0025336204562336206, 1.0]\n"
          ]
        }
      ],
      "source": [
        "losses_balanced = []\n",
        "\n",
        "for d in diseases:\n",
        "  X = balanced_data.copy()\n",
        "  del X['target']\n",
        "  y = X.pop(d)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "  X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.3)\n",
        "\n",
        "  # balance data with SMOTE\n",
        "  X_train, y_train = smote.fit_resample(X_train, y_train.ravel())\n",
        "  X_validation, y_validation = smote.fit_resample(X_validation, y_validation.ravel())\n",
        "\n",
        "  model = SingleLabelNN()\n",
        "  model.fit(\n",
        "      tf.convert_to_tensor(np.asarray(X_train).astype('int')), \n",
        "      tf.convert_to_tensor(y_train),\n",
        "      epochs=40, \n",
        "      batch_size=10\n",
        "  )\n",
        "\n",
        "  # test\n",
        "  test = model.evaluate(tf.convert_to_tensor(np.asarray(X_test).astype('int')), tf.convert_to_tensor(y_test), batch_size=10)\n",
        "\n",
        "  # validation\n",
        "  validation = model.evaluate(tf.convert_to_tensor(np.asarray(X_validation).astype('int')), tf.convert_to_tensor(y_validation), batch_size=10)\n",
        "\n",
        "  losses_balanced.append(f'{d} - Training Loss and Accuracy (test): {test}')\n",
        "  losses_balanced.append(f'{d} - Training Loss and Accuracy (validation): {validation}')\n",
        "\n",
        "  dl_results.append(f\"Balanced data - Single-label {d} NN Loss and Accuracy(test): {test[1]}\")\n",
        "  dl_results.append(f\"Balanced data - Single-label {d} NN Loss and Accuracy(validation): {validation[1]}\")\n",
        "\n",
        "for l in losses_balanced:\n",
        "  print(l)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Machine Learning Results ---\")\n",
        "for line in ml_results:\n",
        "  s = line.split(\",\")\n",
        "  print(s)\n",
        "\n",
        "print(\"--- Deep Learning Results ---\")\n",
        "for line in dl_results:\n",
        "  s = line.split(\",\")\n",
        "  print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBAYtEnf1z29",
        "outputId": "2ce71a8a-ecb9-4a9b-9324-5f5c27080602"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Machine Learning Results ---\n",
            "['Imbalanced data - MLP: 0.4536082474226804']\n",
            "['Imbalanced data - SVM: 0.36082474226804123']\n",
            "['Imbalanced data - RF: 0.41237113402061853']\n",
            "['Imbalanced data - DT: 0.31958762886597936']\n",
            "['Balanced data - MLP: 0.36082474226804123']\n",
            "['Balanced data - SVM: 0.32989690721649484']\n",
            "['Balanced data - RF: 0.36082474226804123']\n",
            "['Balanced data - DT: 0.26804123711340205']\n",
            "--- Deep Learning Results ---\n",
            "['Imbalanced data - Multi-label NN Loss and Accuracy(test): 0.6288659572601318']\n",
            "['Imbalanced data - Multi-label NN Loss and Accuracy(validation): 0.5555555820465088']\n",
            "['Imbalanced data - Single-label Insominia NN Loss and Accuracy(test): 1.0']\n",
            "['Imbalanced data - Single-label Insominia NN Loss and Accuracy(validation): 0.9833333492279053']\n",
            "['Imbalanced data - Single-label shizopherania NN Loss and Accuracy(test): 0.8799999952316284']\n",
            "['Imbalanced data - Single-label shizopherania NN Loss and Accuracy(validation): 0.9083333611488342']\n",
            "['Imbalanced data - Single-label vascula_demetia NN Loss and Accuracy(test): 0.6700000166893005']\n",
            "['Imbalanced data - Single-label vascula_demetia NN Loss and Accuracy(validation): 0.7833333611488342']\n",
            "['Imbalanced data - Single-label MBD NN Loss and Accuracy(test): 0.5699999928474426']\n",
            "['Imbalanced data - Single-label MBD NN Loss and Accuracy(validation): 0.6083333492279053']\n",
            "['Imbalanced data - Single-label Bipolar NN Loss and Accuracy(test): 0.9900000095367432']\n",
            "['Imbalanced data - Single-label Bipolar NN Loss and Accuracy(validation): 0.9750000238418579']\n",
            "['Balanced data - Multi-label NN Loss and Accuracy(test): 0.5144032835960388']\n",
            "['Balanced data - Multi-label NN Loss and Accuracy(validation): 0.5532646179199219']\n",
            "['Balanced data - Single-label Insominia NN Loss and Accuracy(test): 1.0']\n",
            "['Balanced data - Single-label Insominia NN Loss and Accuracy(validation): 1.0']\n",
            "['Balanced data - Single-label shizopherania NN Loss and Accuracy(test): 0.9175257682800293']\n",
            "['Balanced data - Single-label shizopherania NN Loss and Accuracy(validation): 0.9504950642585754']\n",
            "['Balanced data - Single-label vascula_demetia NN Loss and Accuracy(test): 0.7938144207000732']\n",
            "['Balanced data - Single-label vascula_demetia NN Loss and Accuracy(validation): 0.8101266026496887']\n",
            "['Balanced data - Single-label MBD NN Loss and Accuracy(test): 0.6701030731201172']\n",
            "['Balanced data - Single-label MBD NN Loss and Accuracy(validation): 0.6282051205635071']\n",
            "['Balanced data - Single-label Bipolar NN Loss and Accuracy(test): 1.0']\n",
            "['Balanced data - Single-label Bipolar NN Loss and Accuracy(validation): 1.0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i7pR1BES2EgC"
      },
      "execution_count": 33,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UIUC-CS598-S23-TEAM139/23Spring-CS598-Final-Project/blob/main/psychotic_disorder_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6C0abbU4llQB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import io\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# The deep learning model was trained using Keras functional API, \n",
        "# running on top of TensorFlow in Google Colaboratory online platform \n",
        "# with Python 3.6 notebook.\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model, Model, Sequential\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten, Input, MaxPool2D"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Files"
      ],
      "metadata": {
        "id": "wiTPtLRLmIy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to access to the dataset:**\n",
        "\n",
        "Please go the Appendix A of the [paper](https://www.sciencedirect.com/science/article/pii/S2352914821000356#cebib0010) or download through this [link](https://www.sciencedirect.com/science/article/pii/S2352340917303487#ec0010):\n",
        "\n",
        "\n",
        "*   In the section 'Extras', please click on 'Download all' to get the cvs file.\n",
        "*   Click on 'Choose Files' to upload the csv file here.\n",
        "\n"
      ],
      "metadata": {
        "id": "OAKMBmL5uDPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "jJ0IDlaamHgk",
        "outputId": "3343d54a-3a8d-469c-8240-44b64aa6d2a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-576c25c0-7139-4842-b647-6f3d004961d5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-576c25c0-7139-4842-b647-6f3d004961d5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data.csv to data (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(io.BytesIO(uploaded['data.csv']),encoding='cp1252')"
      ],
      "metadata": {
        "id": "csRLfA6kmTjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "mO0ORMD7mljl",
        "outputId": "47ab2f38-c578-46fb-9495-809bd616cdc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sex  age faNoily_status religion occupation genetic status loss_of_parent  \\\n",
              "0     M   18            Yes        C    STUDENT     Yes      S            Yes   \n",
              "1     F   30            Yes        M    ARTISAN     Yes      S            Yes   \n",
              "2     M   22            Yes        C    STUDENT      No      S             No   \n",
              "3     M   35             No        M    ARTISAN      No      M             No   \n",
              "4     M   30            Yes        M    ARTISAN     Yes      M             No   \n",
              "..   ..  ...            ...      ...        ...     ...    ...            ...   \n",
              "495   F   73            Yes        M    RETIRED     Yes      S            Yes   \n",
              "496   F   50             No        M    ARTISAN      No      M            Yes   \n",
              "497   F   32             No        C      FORCE      No      M             No   \n",
              "498   M   13            Yes        C    STUDENT      No      S            Yes   \n",
              "499   F   19            Yes        M    STUDENT      No      S            Yes   \n",
              "\n",
              "    divorse Injury Spiritual_consult Insominia shizopherania vascula_demetia  \\\n",
              "0        No     No               Yes         N             P               P   \n",
              "1        No    Yes               Yes         P             P               P   \n",
              "2        No     No               Yes         P             P               P   \n",
              "3        No     No               Yes         P             P               N   \n",
              "4        No     No               Yes         P             P               P   \n",
              "..      ...    ...               ...       ...           ...             ...   \n",
              "495      No     No               Yes         P             N               P   \n",
              "496      No     No                No         P             P               N   \n",
              "497      No     No               Yes         N             P               P   \n",
              "498      No     No                No         N             P               N   \n",
              "499      No     No               Yes         N             P               P   \n",
              "\n",
              "    MBD Bipolar  agecode  \n",
              "0     P       N        1  \n",
              "1     N       N        1  \n",
              "2     N       P        1  \n",
              "3     N       P        2  \n",
              "4     P       P        1  \n",
              "..   ..     ...      ...  \n",
              "495   N       P        3  \n",
              "496   P       P        2  \n",
              "497   P       N        2  \n",
              "498   N       N        1  \n",
              "499   N       N        1  \n",
              "\n",
              "[500 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47d11d6c-4ca4-4484-9157-f70262bd66f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>faNoily_status</th>\n",
              "      <th>religion</th>\n",
              "      <th>occupation</th>\n",
              "      <th>genetic</th>\n",
              "      <th>status</th>\n",
              "      <th>loss_of_parent</th>\n",
              "      <th>divorse</th>\n",
              "      <th>Injury</th>\n",
              "      <th>Spiritual_consult</th>\n",
              "      <th>Insominia</th>\n",
              "      <th>shizopherania</th>\n",
              "      <th>vascula_demetia</th>\n",
              "      <th>MBD</th>\n",
              "      <th>Bipolar</th>\n",
              "      <th>agecode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>18</td>\n",
              "      <td>Yes</td>\n",
              "      <td>C</td>\n",
              "      <td>STUDENT</td>\n",
              "      <td>Yes</td>\n",
              "      <td>S</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>F</td>\n",
              "      <td>30</td>\n",
              "      <td>Yes</td>\n",
              "      <td>M</td>\n",
              "      <td>ARTISAN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>S</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>22</td>\n",
              "      <td>Yes</td>\n",
              "      <td>C</td>\n",
              "      <td>STUDENT</td>\n",
              "      <td>No</td>\n",
              "      <td>S</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>35</td>\n",
              "      <td>No</td>\n",
              "      <td>M</td>\n",
              "      <td>ARTISAN</td>\n",
              "      <td>No</td>\n",
              "      <td>M</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>30</td>\n",
              "      <td>Yes</td>\n",
              "      <td>M</td>\n",
              "      <td>ARTISAN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>M</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>F</td>\n",
              "      <td>73</td>\n",
              "      <td>Yes</td>\n",
              "      <td>M</td>\n",
              "      <td>RETIRED</td>\n",
              "      <td>Yes</td>\n",
              "      <td>S</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>F</td>\n",
              "      <td>50</td>\n",
              "      <td>No</td>\n",
              "      <td>M</td>\n",
              "      <td>ARTISAN</td>\n",
              "      <td>No</td>\n",
              "      <td>M</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>F</td>\n",
              "      <td>32</td>\n",
              "      <td>No</td>\n",
              "      <td>C</td>\n",
              "      <td>FORCE</td>\n",
              "      <td>No</td>\n",
              "      <td>M</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>M</td>\n",
              "      <td>13</td>\n",
              "      <td>Yes</td>\n",
              "      <td>C</td>\n",
              "      <td>STUDENT</td>\n",
              "      <td>No</td>\n",
              "      <td>S</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>F</td>\n",
              "      <td>19</td>\n",
              "      <td>Yes</td>\n",
              "      <td>M</td>\n",
              "      <td>STUDENT</td>\n",
              "      <td>No</td>\n",
              "      <td>S</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 17 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47d11d6c-4ca4-4484-9157-f70262bd66f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47d11d6c-4ca4-4484-9157-f70262bd66f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47d11d6c-4ca4-4484-9157-f70262bd66f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(df['Bipolar'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDnU2cE7Pny3",
        "outputId": "c0192ba5-7840-4dae-d31d-fa4073535718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'N', 'P'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "CQTqP1qbRF5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encode data**\n",
        "\n",
        "\n",
        "*   The Negative or N values are encoded as 0 and the Positive or P values are encoded as 1.\n",
        "*   Add 'target' column with all combinations with more than 6 occurrences.\n",
        "\n"
      ],
      "metadata": {
        "id": "37rp6d_4v4uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Binary and One-hot encoding for categorial variables\n",
        "\n",
        "# Encode 'sex' (M/F) into binary value\n",
        "df['sex'].replace(['M', 'F'], [0, 1], inplace=True)\n",
        "\n",
        "# Encode 'faNoily_status' (No/Yes) into binary value\n",
        "df['faNoily_status'].replace(['No', 'Yes'], [0, 1], inplace=True)\n",
        "\n",
        "# Encode 'genetic' (No/Yes) into binary value\n",
        "df['genetic'].replace(['No', 'Yes'], [0, 1], inplace=True)\n",
        "\n",
        "# Encode 'status' (S/M) into binary value\n",
        "df['status'].replace(['S', 'M'], [0, 1], inplace=True)\n",
        "\n",
        "# Encode 'loss_of_parent' (No/Yes) into binary value\n",
        "df['loss_of_parent'].replace(['No', 'Yes'], [0, 1], inplace=True)\n",
        "\n",
        "# Encode 'divorse' (No/Yes) into binary value\n",
        "df['divorse'].replace(['No', 'Yes'], [0, 1], inplace=True)\n",
        "\n",
        "# Encode 'Injury' (No/Yes) into binary value\n",
        "df['Injury'].replace(['No', 'Yes'], [0, 1], inplace=True)\n",
        "\n",
        "# Encode 'Spiritual_consult' (No/Yes) into binary value\n",
        "df['Spiritual_consult'].replace(['No', 'Yes'], [0, 1], inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# region\n",
        "dum_religion = pd.get_dummies(df.religion, prefix='religion')\n",
        "df = pd.concat([df, dum_religion], axis=1)\n",
        "df.drop('religion', inplace=True, axis=1)\n",
        "\n",
        "# occupation\n",
        "dum_occ = pd.get_dummies(df.occupation, prefix='occupation')\n",
        "df = pd.concat([df, dum_occ], axis=1)\n",
        "df.drop('occupation', inplace=True, axis=1)\n",
        "\n",
        "# agecode\n",
        "dum_agecode = pd.get_dummies(df.agecode, prefix='agecode')\n",
        "df = pd.concat([df, dum_agecode], axis=1)\n",
        "df.drop('agecode', inplace=True, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "# Insominia (N/P)\n",
        "df['Insominia'].replace(['N', 'P'], [0, 1], inplace=True)\n",
        "\n",
        "# MBD (N/P)\n",
        "df['MBD'].replace(['N', 'P'], [0, 1], inplace=True)\n",
        "\n",
        "# Bipolar (N/P)\n",
        "df['Bipolar'].replace(['N', 'P'], [0, 1], inplace=True)\n",
        "\n",
        "# shizopherania (N/P)\n",
        "df['shizopherania'].replace(['N', 'P'], [0, 1], inplace=True)\n",
        "\n",
        "# vascula_demetia (N/P)\n",
        "df['vascula_demetia'].replace(['N', 'P'], [0, 1], inplace=True)\n",
        "\n",
        "data = df.copy()\n",
        "\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "1dmGaTGoPsjW",
        "outputId": "0a6074b7-daa8-4a7b-a7d0-99cac00c7422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sex  age  faNoily_status  genetic  status  loss_of_parent  divorse  \\\n",
              "0      0   18               1        1       0               1        0   \n",
              "1      1   30               1        1       0               1        0   \n",
              "2      0   22               1        0       0               0        0   \n",
              "3      0   35               0        0       1               0        0   \n",
              "4      0   30               1        1       1               0        0   \n",
              "..   ...  ...             ...      ...     ...             ...      ...   \n",
              "495    1   73               1        1       0               1        0   \n",
              "496    1   50               0        0       1               1        0   \n",
              "497    1   32               0        0       1               0        0   \n",
              "498    0   13               1        0       0               1        0   \n",
              "499    1   19               1        0       0               1        0   \n",
              "\n",
              "     Injury  Spiritual_consult  Insominia  ...  religion_O  \\\n",
              "0         0                  1          0  ...           0   \n",
              "1         1                  1          1  ...           0   \n",
              "2         0                  1          1  ...           0   \n",
              "3         0                  1          1  ...           0   \n",
              "4         0                  1          1  ...           0   \n",
              "..      ...                ...        ...  ...         ...   \n",
              "495       0                  1          1  ...           0   \n",
              "496       0                  0          1  ...           0   \n",
              "497       0                  1          0  ...           0   \n",
              "498       0                  0          0  ...           0   \n",
              "499       0                  1          0  ...           0   \n",
              "\n",
              "     occupation_ARTISAN  occupation_C/SERVANT  occupation_FORCE  \\\n",
              "0                     0                     0                 0   \n",
              "1                     1                     0                 0   \n",
              "2                     0                     0                 0   \n",
              "3                     1                     0                 0   \n",
              "4                     1                     0                 0   \n",
              "..                  ...                   ...               ...   \n",
              "495                   0                     0                 0   \n",
              "496                   1                     0                 0   \n",
              "497                   0                     0                 1   \n",
              "498                   0                     0                 0   \n",
              "499                   0                     0                 0   \n",
              "\n",
              "     occupation_RETIRED  occupation_STUDENT  occupation_UNEMPLYD  agecode_1  \\\n",
              "0                     0                   1                    0          1   \n",
              "1                     0                   0                    0          1   \n",
              "2                     0                   1                    0          1   \n",
              "3                     0                   0                    0          0   \n",
              "4                     0                   0                    0          1   \n",
              "..                  ...                 ...                  ...        ...   \n",
              "495                   1                   0                    0          0   \n",
              "496                   0                   0                    0          0   \n",
              "497                   0                   0                    0          0   \n",
              "498                   0                   1                    0          1   \n",
              "499                   0                   1                    0          1   \n",
              "\n",
              "     agecode_2  agecode_3  \n",
              "0            0          0  \n",
              "1            0          0  \n",
              "2            0          0  \n",
              "3            1          0  \n",
              "4            0          0  \n",
              "..         ...        ...  \n",
              "495          0          1  \n",
              "496          1          0  \n",
              "497          1          0  \n",
              "498          0          0  \n",
              "499          0          0  \n",
              "\n",
              "[500 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74777621-efa4-4d11-985c-58951569fe97\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>faNoily_status</th>\n",
              "      <th>genetic</th>\n",
              "      <th>status</th>\n",
              "      <th>loss_of_parent</th>\n",
              "      <th>divorse</th>\n",
              "      <th>Injury</th>\n",
              "      <th>Spiritual_consult</th>\n",
              "      <th>Insominia</th>\n",
              "      <th>...</th>\n",
              "      <th>religion_O</th>\n",
              "      <th>occupation_ARTISAN</th>\n",
              "      <th>occupation_C/SERVANT</th>\n",
              "      <th>occupation_FORCE</th>\n",
              "      <th>occupation_RETIRED</th>\n",
              "      <th>occupation_STUDENT</th>\n",
              "      <th>occupation_UNEMPLYD</th>\n",
              "      <th>agecode_1</th>\n",
              "      <th>agecode_2</th>\n",
              "      <th>agecode_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>1</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74777621-efa4-4d11-985c-58951569fe97')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-74777621-efa4-4d11-985c-58951569fe97 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-74777621-efa4-4d11-985c-58951569fe97');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our target variables are in this order: Insomnia, schizophrenia, vascular dementia, ADHD and Bi-polar disorder."
      ],
      "metadata": {
        "id": "Qlu4QINEwlLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'] = df['Insominia'].astype(str) + df['shizopherania'].astype(str) + df['vascula_demetia'].astype(str) + df['MBD'].astype(str) + df['Bipolar'].astype(str)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "m5u4fAP2SrGF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "bef52014-28e3-4cd1-877f-509f455ec0ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sex  age  faNoily_status  genetic  status  loss_of_parent  divorse  \\\n",
              "0      0   18               1        1       0               1        0   \n",
              "1      1   30               1        1       0               1        0   \n",
              "2      0   22               1        0       0               0        0   \n",
              "3      0   35               0        0       1               0        0   \n",
              "4      0   30               1        1       1               0        0   \n",
              "..   ...  ...             ...      ...     ...             ...      ...   \n",
              "495    1   73               1        1       0               1        0   \n",
              "496    1   50               0        0       1               1        0   \n",
              "497    1   32               0        0       1               0        0   \n",
              "498    0   13               1        0       0               1        0   \n",
              "499    1   19               1        0       0               1        0   \n",
              "\n",
              "     Injury  Spiritual_consult  Insominia  ...  occupation_ARTISAN  \\\n",
              "0         0                  1          0  ...                   0   \n",
              "1         1                  1          1  ...                   1   \n",
              "2         0                  1          1  ...                   0   \n",
              "3         0                  1          1  ...                   1   \n",
              "4         0                  1          1  ...                   1   \n",
              "..      ...                ...        ...  ...                 ...   \n",
              "495       0                  1          1  ...                   0   \n",
              "496       0                  0          1  ...                   1   \n",
              "497       0                  1          0  ...                   0   \n",
              "498       0                  0          0  ...                   0   \n",
              "499       0                  1          0  ...                   0   \n",
              "\n",
              "     occupation_C/SERVANT  occupation_FORCE  occupation_RETIRED  \\\n",
              "0                       0                 0                   0   \n",
              "1                       0                 0                   0   \n",
              "2                       0                 0                   0   \n",
              "3                       0                 0                   0   \n",
              "4                       0                 0                   0   \n",
              "..                    ...               ...                 ...   \n",
              "495                     0                 0                   1   \n",
              "496                     0                 0                   0   \n",
              "497                     0                 1                   0   \n",
              "498                     0                 0                   0   \n",
              "499                     0                 0                   0   \n",
              "\n",
              "     occupation_STUDENT  occupation_UNEMPLYD  agecode_1  agecode_2  agecode_3  \\\n",
              "0                     1                    0          1          0          0   \n",
              "1                     0                    0          1          0          0   \n",
              "2                     1                    0          1          0          0   \n",
              "3                     0                    0          0          1          0   \n",
              "4                     0                    0          1          0          0   \n",
              "..                  ...                  ...        ...        ...        ...   \n",
              "495                   0                    0          0          0          1   \n",
              "496                   0                    0          0          1          0   \n",
              "497                   0                    0          0          1          0   \n",
              "498                   1                    0          1          0          0   \n",
              "499                   1                    0          1          0          0   \n",
              "\n",
              "     target  \n",
              "0     01110  \n",
              "1     11100  \n",
              "2     11101  \n",
              "3     11001  \n",
              "4     11111  \n",
              "..      ...  \n",
              "495   10101  \n",
              "496   11011  \n",
              "497   01110  \n",
              "498   01000  \n",
              "499   01100  \n",
              "\n",
              "[500 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7baa24e3-a18e-462c-b68e-c73ce55310cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>faNoily_status</th>\n",
              "      <th>genetic</th>\n",
              "      <th>status</th>\n",
              "      <th>loss_of_parent</th>\n",
              "      <th>divorse</th>\n",
              "      <th>Injury</th>\n",
              "      <th>Spiritual_consult</th>\n",
              "      <th>Insominia</th>\n",
              "      <th>...</th>\n",
              "      <th>occupation_ARTISAN</th>\n",
              "      <th>occupation_C/SERVANT</th>\n",
              "      <th>occupation_FORCE</th>\n",
              "      <th>occupation_RETIRED</th>\n",
              "      <th>occupation_STUDENT</th>\n",
              "      <th>occupation_UNEMPLYD</th>\n",
              "      <th>agecode_1</th>\n",
              "      <th>agecode_2</th>\n",
              "      <th>agecode_3</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>01110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>1</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>01110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>01000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>01100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7baa24e3-a18e-462c-b68e-c73ce55310cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7baa24e3-a18e-462c-b68e-c73ce55310cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7baa24e3-a18e-462c-b68e-c73ce55310cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paper page 9 - \"As such, we removed all combinations with less than 6 occurrences.\"\n",
        "df = df.groupby('target').filter(lambda x: len(x) > 6)\n",
        "\n",
        "imbalanced_data = df.copy()\n",
        "# we have 'target' for these values\n",
        "del imbalanced_data['Insominia']\n",
        "del imbalanced_data['shizopherania']\n",
        "del imbalanced_data['vascula_demetia']\n",
        "del imbalanced_data['MBD']\n",
        "del imbalanced_data['Bipolar']\n",
        "\n",
        "balanced_data = df.copy()\n",
        "del balanced_data['target']"
      ],
      "metadata": {
        "id": "1_tKsdzPafM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imbalanced_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "mhyTpoJ87nuO",
        "outputId": "530ca572-15bd-4af2-fa4a-16ec2d8621ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sex  age  faNoily_status  genetic  status  loss_of_parent  divorse  \\\n",
              "0      0   18               1        1       0               1        0   \n",
              "2      0   22               1        0       0               0        0   \n",
              "3      0   35               0        0       1               0        0   \n",
              "4      0   30               1        1       1               0        0   \n",
              "5      1   86               1        0       1               1        0   \n",
              "..   ...  ...             ...      ...     ...             ...      ...   \n",
              "495    1   73               1        1       0               1        0   \n",
              "496    1   50               0        0       1               1        0   \n",
              "497    1   32               0        0       1               0        0   \n",
              "498    0   13               1        0       0               1        0   \n",
              "499    1   19               1        0       0               1        0   \n",
              "\n",
              "     Injury  Spiritual_consult  religion_C  ...  occupation_ARTISAN  \\\n",
              "0         0                  1           1  ...                   0   \n",
              "2         0                  1           1  ...                   0   \n",
              "3         0                  1           0  ...                   1   \n",
              "4         0                  1           0  ...                   1   \n",
              "5         0                  1           1  ...                   0   \n",
              "..      ...                ...         ...  ...                 ...   \n",
              "495       0                  1           0  ...                   0   \n",
              "496       0                  0           0  ...                   1   \n",
              "497       0                  1           1  ...                   0   \n",
              "498       0                  0           1  ...                   0   \n",
              "499       0                  1           0  ...                   0   \n",
              "\n",
              "     occupation_C/SERVANT  occupation_FORCE  occupation_RETIRED  \\\n",
              "0                       0                 0                   0   \n",
              "2                       0                 0                   0   \n",
              "3                       0                 0                   0   \n",
              "4                       0                 0                   0   \n",
              "5                       0                 0                   1   \n",
              "..                    ...               ...                 ...   \n",
              "495                     0                 0                   1   \n",
              "496                     0                 0                   0   \n",
              "497                     0                 1                   0   \n",
              "498                     0                 0                   0   \n",
              "499                     0                 0                   0   \n",
              "\n",
              "     occupation_STUDENT  occupation_UNEMPLYD  agecode_1  agecode_2  agecode_3  \\\n",
              "0                     1                    0          1          0          0   \n",
              "2                     1                    0          1          0          0   \n",
              "3                     0                    0          0          1          0   \n",
              "4                     0                    0          1          0          0   \n",
              "5                     0                    0          0          0          1   \n",
              "..                  ...                  ...        ...        ...        ...   \n",
              "495                   0                    0          0          0          1   \n",
              "496                   0                    0          0          1          0   \n",
              "497                   0                    0          0          1          0   \n",
              "498                   1                    0          1          0          0   \n",
              "499                   1                    0          1          0          0   \n",
              "\n",
              "     target  \n",
              "0     01110  \n",
              "2     11101  \n",
              "3     11001  \n",
              "4     11111  \n",
              "5     01100  \n",
              "..      ...  \n",
              "495   10101  \n",
              "496   11011  \n",
              "497   01110  \n",
              "498   01000  \n",
              "499   01100  \n",
              "\n",
              "[484 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6fc78c9e-13c6-42fe-a35b-0fc7712b5154\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>faNoily_status</th>\n",
              "      <th>genetic</th>\n",
              "      <th>status</th>\n",
              "      <th>loss_of_parent</th>\n",
              "      <th>divorse</th>\n",
              "      <th>Injury</th>\n",
              "      <th>Spiritual_consult</th>\n",
              "      <th>religion_C</th>\n",
              "      <th>...</th>\n",
              "      <th>occupation_ARTISAN</th>\n",
              "      <th>occupation_C/SERVANT</th>\n",
              "      <th>occupation_FORCE</th>\n",
              "      <th>occupation_RETIRED</th>\n",
              "      <th>occupation_STUDENT</th>\n",
              "      <th>occupation_UNEMPLYD</th>\n",
              "      <th>agecode_1</th>\n",
              "      <th>agecode_2</th>\n",
              "      <th>agecode_3</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>01110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>01100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>1</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>01110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>01000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>01100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>484 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fc78c9e-13c6-42fe-a35b-0fc7712b5154')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6fc78c9e-13c6-42fe-a35b-0fc7712b5154 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6fc78c9e-13c6-42fe-a35b-0fc7712b5154');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use 'Insominia' data"
      ],
      "metadata": {
        "id": "8he85tT3RN5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_data['Insominia']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG4Jdh_vRUV_",
        "outputId": "7c32a6bd-6a74-44fe-8641-f86e8b0fae87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "2      1\n",
              "3      1\n",
              "4      1\n",
              "5      0\n",
              "      ..\n",
              "495    1\n",
              "496    1\n",
              "497    0\n",
              "498    0\n",
              "499    0\n",
              "Name: Insominia, Length: 484, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Balance dataset with SMOTE\n",
        "Just try SMOTE\n"
      ],
      "metadata": {
        "id": "phkra0YKsS0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y = balanced_data.pop('Insominia')\n",
        "# X = balanced_data\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "# X_train  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "k6xaGUu6R_U0",
        "outputId": "1129bd74-70a3-4a94-c2a9-90bfc5528edf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sex  age  faNoily_status  genetic  status  loss_of_parent  divorse  \\\n",
              "345    0   34               0        0       1               0        0   \n",
              "44     1   34               0        1       1               1        0   \n",
              "129    0   50               1        0       1               0        0   \n",
              "102    0   21               0        0       0               0        0   \n",
              "420    0   30               1        1       0               1        0   \n",
              "..   ...  ...             ...      ...     ...             ...      ...   \n",
              "290    1   25               0        0       0               0        0   \n",
              "394    1   56               1        1       1               1        0   \n",
              "344    1   50               1        1       1               1        0   \n",
              "204    1   26               1        0       0               0        0   \n",
              "294    1   34               0        1       1               0        0   \n",
              "\n",
              "     Injury  Spiritual_consult  shizopherania  ...  agecode  C  M  O  ARTISAN  \\\n",
              "345       0                  1              1  ...        2  0  1  0        0   \n",
              "44        0                  0              1  ...        2  1  0  0        0   \n",
              "129       0                  0              1  ...        2  1  0  0        1   \n",
              "102       0                  1              1  ...        1  0  0  1        0   \n",
              "420       0                  0              1  ...        1  1  0  0        0   \n",
              "..      ...                ...            ...  ...      ... .. .. ..      ...   \n",
              "290       0                  1              1  ...        1  0  1  0        0   \n",
              "394       1                  0              1  ...        3  1  0  0        0   \n",
              "344       1                  1              1  ...        2  1  0  0        1   \n",
              "204       0                  1              1  ...        1  1  0  0        1   \n",
              "294       0                  0              1  ...        2  1  0  0        0   \n",
              "\n",
              "     C/SERVANT  FORCE  RETIRED  STUDENT  UNEMPLYD  \n",
              "345          0      0        0        1         0  \n",
              "44           0      0        0        0         1  \n",
              "129          0      0        0        0         0  \n",
              "102          0      0        0        1         0  \n",
              "420          0      0        0        0         1  \n",
              "..         ...    ...      ...      ...       ...  \n",
              "290          0      0        0        0         1  \n",
              "394          1      0        0        0         0  \n",
              "344          0      0        0        0         0  \n",
              "204          0      0        0        0         0  \n",
              "294          0      0        0        0         1  \n",
              "\n",
              "[338 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1565cd0b-c3f4-45e9-877d-44dbe9f048da\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>faNoily_status</th>\n",
              "      <th>genetic</th>\n",
              "      <th>status</th>\n",
              "      <th>loss_of_parent</th>\n",
              "      <th>divorse</th>\n",
              "      <th>Injury</th>\n",
              "      <th>Spiritual_consult</th>\n",
              "      <th>shizopherania</th>\n",
              "      <th>...</th>\n",
              "      <th>agecode</th>\n",
              "      <th>C</th>\n",
              "      <th>M</th>\n",
              "      <th>O</th>\n",
              "      <th>ARTISAN</th>\n",
              "      <th>C/SERVANT</th>\n",
              "      <th>FORCE</th>\n",
              "      <th>RETIRED</th>\n",
              "      <th>STUDENT</th>\n",
              "      <th>UNEMPLYD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>1</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>338 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1565cd0b-c3f4-45e9-877d-44dbe9f048da')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1565cd0b-c3f4-45e9-877d-44dbe9f048da button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1565cd0b-c3f4-45e9-877d-44dbe9f048da');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# every sample had a total of 101 samples each\n",
        "# smote = SMOTE(random_state=101)\n",
        "# X_train_balance, y_train_balance = smote.fit_resample(X_train, y_train.values.ravel())\n",
        "# X_train_balance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "tTzwXqF8SdNg",
        "outputId": "27555655-5db3-43ba-9bae-7344337c1e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sex  age  faNoily_status  genetic  status  loss_of_parent  divorse  \\\n",
              "0      0   34               0        0       1               0        0   \n",
              "1      1   34               0        1       1               1        0   \n",
              "2      0   50               1        0       1               0        0   \n",
              "3      0   21               0        0       0               0        0   \n",
              "4      0   30               1        1       0               1        0   \n",
              "..   ...  ...             ...      ...     ...             ...      ...   \n",
              "417    0   27               0        0       0               0        0   \n",
              "418    1   20               0        0       0               0        0   \n",
              "419    0   54               1        0       1               0        0   \n",
              "420    0   45               1        0       1               1        0   \n",
              "421    0   30               0        0       1               0        0   \n",
              "\n",
              "     Injury  Spiritual_consult  shizopherania  ...  agecode  C  M  O  ARTISAN  \\\n",
              "0         0                  1              1  ...        2  0  1  0        0   \n",
              "1         0                  0              1  ...        2  1  0  0        0   \n",
              "2         0                  0              1  ...        2  1  0  0        1   \n",
              "3         0                  1              1  ...        1  0  0  1        0   \n",
              "4         0                  0              1  ...        1  1  0  0        0   \n",
              "..      ...                ...            ...  ...      ... .. .. ..      ...   \n",
              "417       0                  1              1  ...        1  0  0  0        0   \n",
              "418       0                  1              1  ...        1  0  0  0        0   \n",
              "419       1                  0              0  ...        3  0  1  0        0   \n",
              "420       0                  1              1  ...        2  1  0  0        1   \n",
              "421       0                  1              1  ...        1  0  0  1        0   \n",
              "\n",
              "     C/SERVANT  FORCE  RETIRED  STUDENT  UNEMPLYD  \n",
              "0            0      0        0        1         0  \n",
              "1            0      0        0        0         1  \n",
              "2            0      0        0        0         0  \n",
              "3            0      0        0        1         0  \n",
              "4            0      0        0        0         1  \n",
              "..         ...    ...      ...      ...       ...  \n",
              "417          0      0        0        1         0  \n",
              "418          0      0        0        1         0  \n",
              "419          0      0        0        0         0  \n",
              "420          0      0        0        0         0  \n",
              "421          0      0        0        0         0  \n",
              "\n",
              "[422 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-652a5107-7113-4308-a9aa-b953163d92be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>faNoily_status</th>\n",
              "      <th>genetic</th>\n",
              "      <th>status</th>\n",
              "      <th>loss_of_parent</th>\n",
              "      <th>divorse</th>\n",
              "      <th>Injury</th>\n",
              "      <th>Spiritual_consult</th>\n",
              "      <th>shizopherania</th>\n",
              "      <th>...</th>\n",
              "      <th>agecode</th>\n",
              "      <th>C</th>\n",
              "      <th>M</th>\n",
              "      <th>O</th>\n",
              "      <th>ARTISAN</th>\n",
              "      <th>C/SERVANT</th>\n",
              "      <th>FORCE</th>\n",
              "      <th>RETIRED</th>\n",
              "      <th>STUDENT</th>\n",
              "      <th>UNEMPLYD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418</th>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>422 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-652a5107-7113-4308-a9aa-b953163d92be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-652a5107-7113-4308-a9aa-b953163d92be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-652a5107-7113-4308-a9aa-b953163d92be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Label Classification Model on dataset with class imbalance."
      ],
      "metadata": {
        "id": "60xX3SfWceIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine learning"
      ],
      "metadata": {
        "id": "fumFpAYshUFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "jN-7jXPMVTGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a Multilayer Perceptron (MLP), Support Vector Machines (SVM), Random Forest (RF) and Decision Tree (DT) on the training data (which is 80% of the whole data). The four algorithms are evaluated on the test set (which is 20% of the sampled data). The accuracy and balanced accuracy are as presented in Table 3.\n",
        "\n",
        "![Table 3.png](data:image/png;base64,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)\n"
      ],
      "metadata": {
        "id": "b39OnB92bpK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp = imbalanced_data.copy()\n",
        "y_multi_imbalanced = temp.pop('target')\n",
        "X_multi_imbalanced = temp\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_multi_imbalanced, y_multi_imbalanced, test_size=0.2)"
      ],
      "metadata": {
        "id": "zY8wh-G3XXtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []"
      ],
      "metadata": {
        "id": "3whzW2UW17n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multilayer Perceptron (MLP)"
      ],
      "metadata": {
        "id": "fnACvLuiefAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MLP = MLPClassifier()\n",
        "MLP.fit(X_train, y_train)\n",
        "mlp_score = MLP.score(X_test, y_test)\n",
        "results.append(f\"Imbalanced data - MLP: {mlp_score}\")\n",
        "print(f\"MLP for imbalanced data = {mlp_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkzS6vxobomM",
        "outputId": "f30951d3-f357-4d30-80f8-1f4ac8e12c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP for imbalanced data = 0.4742268041237113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machines (SVM)"
      ],
      "metadata": {
        "id": "M74LfhMUeihO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svc = LinearSVC()\n",
        "svc.fit(X_train, y_train)\n",
        "svm_score = svc.score(X_test, y_test)\n",
        "results.append(f\"Imbalanced data - SVM: {svm_score}\")\n",
        "print(f\"SVM for imbalanced data = {svm_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AST0fEdFeagq",
        "outputId": "0f9077f6-ee97-4a71-d799-578f313f071c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM for imbalanced data = 0.26804123711340205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest (RF)"
      ],
      "metadata": {
        "id": "BY-WLST_elEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RF = RandomForestClassifier()\n",
        "RF.fit(X_train, y_train)\n",
        "rf_score = RF.score(X_test, y_test)\n",
        "results.append(f\"Imbalanced data - RF: {rf_score}\")\n",
        "print(f\"RF for imbalanced data = {rf_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIrOLjSjeobC",
        "outputId": "42f31d91-aedb-42ef-f506-12a1ec7896c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF for imbalanced data = 0.36082474226804123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree (DT)"
      ],
      "metadata": {
        "id": "wDrn5ALEe4Vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decistion_tree = DecisionTreeClassifier()\n",
        "decistion_tree.fit(X_train, y_train)\n",
        "dt_score = decistion_tree.score(X_test, y_test)\n",
        "results.append(f\"Imbalanced data - DT: {dt_score}\")\n",
        "print(f\"DT for imbalanced data = {dt_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-rhjK-7e0P4",
        "outputId": "df8f4f0a-3968-4e6b-c1f7-3300b176dadd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DT for imbalanced data = 0.32989690721649484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep learning using Neural Network\n"
      ],
      "metadata": {
        "id": "Qtdij27vhZZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Neural Network in this paper:\n",
        "https://keras.io/guides/sequential_model/\n",
        "\n",
        "The architectural setup presented in Fig. 4a and b are 3-layer deep fully-connected network with the RELU activation function and architectural layer are 15–20–20-40–1 and 15-20–20-40–5 respectively. The training data is split into a 30% validation set running for 40 epochs with an early stop monitor on validation loss. The optimizer is Adam with a learning rate of 0.01.\n",
        "\n",
        "\n",
        "*   Drop-out is chosen over L1 and L2 regularisation in this study\n",
        "*   Sigmoid and ReLU is the activation function used in this study.\n",
        "*   Optimizer is Adam with a learning rate of 0.01.\n",
        "*   The loss function for training is a binary cross-entropy and evaluation metrics accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "phyKh24iq2hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MultiLabelNN():\n",
        "  # Create 3 layers\n",
        "  # page 5 - Fig 4.\n",
        "  # found shape=(10, 22)\n",
        "  input = Dense(15, input_dim=22, activation=\"relu\", name=\"Input\")\n",
        "  hidden_layer1 = Dense(20, activation=\"relu\", name=\"layer1\")\n",
        "  hidden_layer2 = Dense(20, activation=\"relu\", name=\"layer2\") \n",
        "  hidden_layer3 = Dense(40, activation=\"relu\", name=\"layer3\") \n",
        "  output = Dense(5, activation=\"sigmoid\", name=\"Output\") \n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(input)\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(hidden_layer1)\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(hidden_layer2)\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(hidden_layer3)\n",
        "  model.add(output)\n",
        "\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "9uaf5__u9qky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = df.copy()\n",
        "y_multi_nn = pd.DataFrame([temp.pop(x) for x in ['Insominia', 'shizopherania', 'vascula_demetia', 'MBD', 'Bipolar']]).T\n",
        "\n",
        "X_multi_nn = temp\n",
        "\n",
        "# test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_multi_nn, y_multi_nn, test_size=0.2)\n",
        "\n",
        "# validation\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.3)\n",
        "\n",
        "model = MultiLabelNN()\n",
        "model.fit(\n",
        "    tf.convert_to_tensor(np.asarray(X_train).astype('int')), \n",
        "    tf.convert_to_tensor(y_train),\n",
        "    epochs=40, \n",
        "    batch_size=10\n",
        ")\n",
        "\n",
        "# test\n",
        "test = model.evaluate(tf.convert_to_tensor(np.asarray(X_test).astype('int')), tf.convert_to_tensor(y_test), batch_size=10)\n",
        "\n",
        "# validation\n",
        "validation = model.evaluate(tf.convert_to_tensor(np.asarray(X_validation).astype('int')), tf.convert_to_tensor(y_validation), batch_size=10)\n",
        "\n",
        "print(f'Training Loss and Accuracy (test): {test}')\n",
        "print(f'Training Loss and Accuracy (validation): {validation}')\n",
        "results.append(f\"Imbalanced data - Multi-label NN Loss and Accuracy(test): {test}\")\n",
        "results.append(f\"Imbalanced data - Multi-label NN Loss and Accuracy(validation): {validation}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IasS_hfXhdUY",
        "outputId": "eff2e9d6-6592-496c-e9ca-5f9b292deec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "27/27 [==============================] - 1s 3ms/step - loss: 36.2299 - accuracy: 0.3222\n",
            "Epoch 2/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.6928 - accuracy: 0.4852\n",
            "Epoch 3/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9265 - accuracy: 0.5370\n",
            "Epoch 4/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8785 - accuracy: 0.5778\n",
            "Epoch 5/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.5741\n",
            "Epoch 6/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.5926\n",
            "Epoch 7/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.5815\n",
            "Epoch 8/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6006 - accuracy: 0.5778\n",
            "Epoch 9/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6722 - accuracy: 0.5852\n",
            "Epoch 10/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.5926\n",
            "Epoch 11/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.5889\n",
            "Epoch 12/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.5852\n",
            "Epoch 13/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.5926\n",
            "Epoch 14/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6650 - accuracy: 0.5815\n",
            "Epoch 15/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.5815\n",
            "Epoch 16/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.5889\n",
            "Epoch 17/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.5889\n",
            "Epoch 18/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.5778\n",
            "Epoch 19/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.5852\n",
            "Epoch 20/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.5889\n",
            "Epoch 21/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.5926\n",
            "Epoch 22/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.5889\n",
            "Epoch 23/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.5889\n",
            "Epoch 24/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.5889\n",
            "Epoch 25/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.5889\n",
            "Epoch 26/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.5926\n",
            "Epoch 27/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.5963\n",
            "Epoch 28/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.5926\n",
            "Epoch 29/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.5963\n",
            "Epoch 30/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.5926\n",
            "Epoch 31/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.5963\n",
            "Epoch 32/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5850 - accuracy: 0.5963\n",
            "Epoch 33/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.5889\n",
            "Epoch 34/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.5963\n",
            "Epoch 35/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.5926\n",
            "Epoch 36/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5763 - accuracy: 0.5926\n",
            "Epoch 37/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.5963\n",
            "Epoch 38/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8343 - accuracy: 0.5815\n",
            "Epoch 39/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.5852\n",
            "Epoch 40/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.5852\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.5556\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6237 - accuracy: 0.5052\n",
            "Training Loss and Accuracy (test): [0.6072657704353333, 0.5555555820465088]\n",
            "Training Loss and Accuracy (validation): [0.6236616969108582, 0.5051546096801758]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single-Label Classification Model on dataset with class imbalance\n",
        "Using Neural Network with 3-layer"
      ],
      "metadata": {
        "id": "kEvE3sqiqNaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SingleLabelNN():\n",
        "  # Create 3 layers\n",
        "  # page 5 - Fig 4.\n",
        "  # found shape=(10, 25)\n",
        "  input = Dense(15, input_dim=25, activation=\"relu\", name=\"Input\")\n",
        "  hidden_layer1 = Dense(20, activation=\"relu\", name=\"layer1\")\n",
        "  hidden_layer2 = Dense(40, activation=\"relu\", name=\"layer2\") \n",
        "  hidden_layer3 = Dense(50, activation=\"relu\", name=\"layer3\") \n",
        "  output = Dense(1, activation=\"sigmoid\", name=\"Output\") \n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(input)\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(hidden_layer1)\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(hidden_layer2)\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(hidden_layer3)\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(output)\n",
        "\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "JVfdAtXLinie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diseases = ['Insominia', 'shizopherania', 'vascula_demetia', 'MBD', 'Bipolar']\n",
        "\n",
        "losses = []\n",
        "\n",
        "for d in diseases:\n",
        "  X = data.copy()\n",
        "  y = X.pop(d)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "  X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.3)\n",
        "\n",
        "  model = SingleLabelNN()\n",
        "  model.fit(\n",
        "      tf.convert_to_tensor(np.asarray(X_train).astype('int')), \n",
        "      tf.convert_to_tensor(y_train),\n",
        "      epochs=40, \n",
        "      batch_size=10\n",
        "  )\n",
        "\n",
        "  # test\n",
        "  test = model.evaluate(tf.convert_to_tensor(np.asarray(X_test).astype('int')), tf.convert_to_tensor(y_test), batch_size=10)\n",
        "\n",
        "  # validation\n",
        "  validation = model.evaluate(tf.convert_to_tensor(np.asarray(X_validation).astype('int')), tf.convert_to_tensor(y_validation), batch_size=10)\n",
        "\n",
        "  losses.append(f'{d} - Training Loss and Accuracy (test): {test}')\n",
        "  losses.append(f'{d} - Training Loss and Accuracy (validation): {validation}')\n",
        "  results.append(f\"Imbalanced data - Single-label {d} NN Loss and Accuracy(test): {test}\")\n",
        "  results.append(f\"Imbalanced data - Single-label {d} NN Loss and Accuracy(validation): {validation}\")\n",
        "\n",
        "for l in losses:\n",
        "  print(l)"
      ],
      "metadata": {
        "id": "MKafpuATql-b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1ce00d0-e443-4467-a4bc-68ff13424e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "28/28 [==============================] - 3s 2ms/step - loss: 0.8390 - accuracy: 0.5464\n",
            "Epoch 2/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6864 - accuracy: 0.5607\n",
            "Epoch 3/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6845 - accuracy: 0.6071\n",
            "Epoch 4/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.5964\n",
            "Epoch 5/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.6607\n",
            "Epoch 6/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6107\n",
            "Epoch 7/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7786\n",
            "Epoch 8/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8321\n",
            "Epoch 9/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.9071\n",
            "Epoch 10/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9786\n",
            "Epoch 11/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9571\n",
            "Epoch 12/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.9393\n",
            "Epoch 13/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1572 - accuracy: 0.9643\n",
            "Epoch 14/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1831 - accuracy: 0.9643\n",
            "Epoch 15/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1344 - accuracy: 0.9643\n",
            "Epoch 16/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1234 - accuracy: 0.9607\n",
            "Epoch 17/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1636 - accuracy: 0.9571\n",
            "Epoch 18/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1683 - accuracy: 0.9321\n",
            "Epoch 19/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.9821\n",
            "Epoch 20/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1109 - accuracy: 0.9714\n",
            "Epoch 21/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 0.9571\n",
            "Epoch 22/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.9500\n",
            "Epoch 23/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1578 - accuracy: 0.9643\n",
            "Epoch 24/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1145 - accuracy: 0.9714\n",
            "Epoch 25/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1163 - accuracy: 0.9643\n",
            "Epoch 26/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1161 - accuracy: 0.9714\n",
            "Epoch 27/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1508 - accuracy: 0.9536\n",
            "Epoch 28/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9893\n",
            "Epoch 29/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.9714\n",
            "Epoch 30/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1204 - accuracy: 0.9714\n",
            "Epoch 31/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1069 - accuracy: 0.9714\n",
            "Epoch 32/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1582 - accuracy: 0.9500\n",
            "Epoch 33/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1806 - accuracy: 0.9357\n",
            "Epoch 34/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.9714\n",
            "Epoch 35/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1045 - accuracy: 0.9643\n",
            "Epoch 36/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 0.9679\n",
            "Epoch 37/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1136 - accuracy: 0.9643\n",
            "Epoch 38/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0973 - accuracy: 0.9786\n",
            "Epoch 39/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1014 - accuracy: 0.9643\n",
            "Epoch 40/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1448 - accuracy: 0.9429\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9667\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.9400\n",
            "Epoch 1/40\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 0.6910 - accuracy: 0.8179\n",
            "Epoch 2/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.8536\n",
            "Epoch 3/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.8536\n",
            "Epoch 4/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8536\n",
            "Epoch 5/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8536\n",
            "Epoch 6/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8679\n",
            "Epoch 7/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8750\n",
            "Epoch 8/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.8786\n",
            "Epoch 9/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8714\n",
            "Epoch 10/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8821\n",
            "Epoch 11/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3477 - accuracy: 0.8679\n",
            "Epoch 12/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3376 - accuracy: 0.8821\n",
            "Epoch 13/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.8643\n",
            "Epoch 14/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3377 - accuracy: 0.8500\n",
            "Epoch 15/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8929\n",
            "Epoch 16/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3326 - accuracy: 0.8536\n",
            "Epoch 17/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2874 - accuracy: 0.8857\n",
            "Epoch 18/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3381 - accuracy: 0.8821\n",
            "Epoch 19/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3160 - accuracy: 0.9036\n",
            "Epoch 20/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.9000\n",
            "Epoch 21/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2920 - accuracy: 0.8821\n",
            "Epoch 22/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2711 - accuracy: 0.8857\n",
            "Epoch 23/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2944 - accuracy: 0.9036\n",
            "Epoch 24/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2888 - accuracy: 0.8929\n",
            "Epoch 25/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2999 - accuracy: 0.9000\n",
            "Epoch 26/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2933 - accuracy: 0.8929\n",
            "Epoch 27/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2750 - accuracy: 0.8821\n",
            "Epoch 28/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2803 - accuracy: 0.8929\n",
            "Epoch 29/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.8964\n",
            "Epoch 30/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8536\n",
            "Epoch 31/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3124 - accuracy: 0.9107\n",
            "Epoch 32/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3065 - accuracy: 0.8857\n",
            "Epoch 33/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2596 - accuracy: 0.8929\n",
            "Epoch 34/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2724 - accuracy: 0.8929\n",
            "Epoch 35/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3282 - accuracy: 0.8857\n",
            "Epoch 36/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2826 - accuracy: 0.8893\n",
            "Epoch 37/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3453 - accuracy: 0.8821\n",
            "Epoch 38/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3188 - accuracy: 0.8929\n",
            "Epoch 39/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8893\n",
            "Epoch 40/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3158 - accuracy: 0.8786\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.9083\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.9300\n",
            "Epoch 1/40\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.8126 - accuracy: 0.6286\n",
            "Epoch 2/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.6321\n",
            "Epoch 3/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.6821\n",
            "Epoch 4/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6821\n",
            "Epoch 5/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.6821\n",
            "Epoch 6/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.6821\n",
            "Epoch 7/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6322 - accuracy: 0.6786\n",
            "Epoch 8/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6095 - accuracy: 0.6786\n",
            "Epoch 9/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.6714\n",
            "Epoch 10/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.6821\n",
            "Epoch 11/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.6857\n",
            "Epoch 12/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.6893\n",
            "Epoch 13/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.6821\n",
            "Epoch 14/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.6571\n",
            "Epoch 15/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.6821\n",
            "Epoch 16/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.6821\n",
            "Epoch 17/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.6964\n",
            "Epoch 18/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.6750\n",
            "Epoch 19/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5889 - accuracy: 0.6857\n",
            "Epoch 20/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.6786\n",
            "Epoch 21/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.6964\n",
            "Epoch 22/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7393\n",
            "Epoch 23/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.7071\n",
            "Epoch 24/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.6786\n",
            "Epoch 25/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.6821\n",
            "Epoch 26/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.6607\n",
            "Epoch 27/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.7214\n",
            "Epoch 28/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7679\n",
            "Epoch 29/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.6929\n",
            "Epoch 30/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.6857\n",
            "Epoch 31/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7000\n",
            "Epoch 32/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7429\n",
            "Epoch 33/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.6786\n",
            "Epoch 34/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7214\n",
            "Epoch 35/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7071\n",
            "Epoch 36/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.7464\n",
            "Epoch 37/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4972 - accuracy: 0.7750\n",
            "Epoch 38/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7571\n",
            "Epoch 39/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7679\n",
            "Epoch 40/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7607\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8250\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8200\n",
            "Epoch 1/40\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.7976 - accuracy: 0.5250\n",
            "Epoch 2/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.5750\n",
            "Epoch 3/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.5393\n",
            "Epoch 4/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6660 - accuracy: 0.5857\n",
            "Epoch 5/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6784 - accuracy: 0.5679\n",
            "Epoch 6/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6482 - accuracy: 0.5893\n",
            "Epoch 7/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6646 - accuracy: 0.6107\n",
            "Epoch 8/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.6214\n",
            "Epoch 9/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6214\n",
            "Epoch 10/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.5964\n",
            "Epoch 11/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6761 - accuracy: 0.5929\n",
            "Epoch 12/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.6321\n",
            "Epoch 13/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.6500\n",
            "Epoch 14/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.6429\n",
            "Epoch 15/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.6607\n",
            "Epoch 16/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.6429\n",
            "Epoch 17/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.6607\n",
            "Epoch 18/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.6179\n",
            "Epoch 19/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.6571\n",
            "Epoch 20/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.6964\n",
            "Epoch 21/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5700 - accuracy: 0.6964\n",
            "Epoch 22/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.6893\n",
            "Epoch 23/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.7143\n",
            "Epoch 24/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.7357\n",
            "Epoch 25/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7179\n",
            "Epoch 26/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.7000\n",
            "Epoch 27/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.7071\n",
            "Epoch 28/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.7214\n",
            "Epoch 29/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.7107\n",
            "Epoch 30/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.7143\n",
            "Epoch 31/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.6893\n",
            "Epoch 32/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.6821\n",
            "Epoch 33/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.7179\n",
            "Epoch 34/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7357\n",
            "Epoch 35/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.7250\n",
            "Epoch 36/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.7214\n",
            "Epoch 37/40\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 0.5533 - accuracy: 0.7143\n",
            "Epoch 38/40\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.5757 - accuracy: 0.7071\n",
            "Epoch 39/40\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.5557 - accuracy: 0.7393\n",
            "Epoch 40/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5663 - accuracy: 0.7250\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.5917\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6263 - accuracy: 0.6500\n",
            "Epoch 1/40\n",
            "28/28 [==============================] - 2s 2ms/step - loss: 0.9809 - accuracy: 0.5071\n",
            "Epoch 2/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.5857\n",
            "Epoch 3/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.5714\n",
            "Epoch 4/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.6286\n",
            "Epoch 5/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6714\n",
            "Epoch 6/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.6857\n",
            "Epoch 7/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.7536\n",
            "Epoch 8/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7571\n",
            "Epoch 9/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8500\n",
            "Epoch 10/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.9214\n",
            "Epoch 11/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.9143\n",
            "Epoch 12/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9464\n",
            "Epoch 13/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9464\n",
            "Epoch 14/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9571\n",
            "Epoch 15/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.9750\n",
            "Epoch 16/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.9321\n",
            "Epoch 17/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.9071\n",
            "Epoch 18/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2177 - accuracy: 0.9286\n",
            "Epoch 19/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2413 - accuracy: 0.9214\n",
            "Epoch 20/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8964\n",
            "Epoch 21/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 0.9607\n",
            "Epoch 22/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1620 - accuracy: 0.9571\n",
            "Epoch 23/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0896 - accuracy: 0.9786\n",
            "Epoch 24/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 0.9714\n",
            "Epoch 25/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.9679\n",
            "Epoch 26/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1188 - accuracy: 0.9679\n",
            "Epoch 27/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0761 - accuracy: 0.9786\n",
            "Epoch 28/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9893\n",
            "Epoch 29/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1189 - accuracy: 0.9714\n",
            "Epoch 30/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9679\n",
            "Epoch 31/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0753 - accuracy: 0.9857\n",
            "Epoch 32/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0932 - accuracy: 0.9750\n",
            "Epoch 33/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.9857\n",
            "Epoch 34/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.9214\n",
            "Epoch 35/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0922 - accuracy: 0.9821\n",
            "Epoch 36/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1419 - accuracy: 0.9643\n",
            "Epoch 37/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 0.9536\n",
            "Epoch 38/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9750\n",
            "Epoch 39/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.9714\n",
            "Epoch 40/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1123 - accuracy: 0.9679\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0866 - accuracy: 0.9917\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.9900\n",
            "Insominia - Training Loss and Accuracy (test): [0.18677012622356415, 0.9666666388511658]\n",
            "Insominia - Training Loss and Accuracy (validation): [0.19448122382164001, 0.9399999976158142]\n",
            "shizopherania - Training Loss and Accuracy (test): [0.26019424200057983, 0.9083333611488342]\n",
            "shizopherania - Training Loss and Accuracy (validation): [0.25901296734809875, 0.9300000071525574]\n",
            "vascula_demetia - Training Loss and Accuracy (test): [0.42520761489868164, 0.824999988079071]\n",
            "vascula_demetia - Training Loss and Accuracy (validation): [0.4311346709728241, 0.8199999928474426]\n",
            "MBD - Training Loss and Accuracy (test): [0.6460111141204834, 0.5916666388511658]\n",
            "MBD - Training Loss and Accuracy (validation): [0.6263187527656555, 0.6499999761581421]\n",
            "Bipolar - Training Loss and Accuracy (test): [0.08656129986047745, 0.9916666746139526]\n",
            "Bipolar - Training Loss and Accuracy (validation): [0.0928097814321518, 0.9900000095367432]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Label Classification Model on dataset without class imbalance"
      ],
      "metadata": {
        "id": "HKFRCiovfFto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp = imbalanced_data.copy()\n",
        "y_balanced = temp.pop('target')\n",
        "X_balanced = temp\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2)\n",
        "\n",
        "# balance data using SMOTE\n",
        "smote = SMOTE()\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "bMf0-VLkfNTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multilayer Perceptron (MLP)"
      ],
      "metadata": {
        "id": "t4-pDWMyfNTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MLP = MLPClassifier()\n",
        "MLP.fit(X_train_balanced, y_train_balanced)\n",
        "mlp_score = MLP.score(X_test, y_test)\n",
        "results.append(f\"Balanced data - MLP: {mlp_score}\")\n",
        "print(f\"MLP for balanced data = {mlp_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pIEXwPVgHvN",
        "outputId": "4fd500cd-f36a-44fd-d71a-f9a992228c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP for balanced data = 0.3711340206185567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machines (SVM)"
      ],
      "metadata": {
        "id": "l1SSfz4GfNTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svc = LinearSVC()\n",
        "svc.fit(X_train_balanced, y_train_balanced)\n",
        "svm_score = svc.score(X_test, y_test)\n",
        "results.append(f\"Balanced data - SVM: {svm_score}\")\n",
        "print(f\"SVM for balanced data = {svm_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e81b4ccd-570c-4c78-87e7-45f3debfc3c3",
        "id": "lMgTnliHfNTt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM for balanced data = 0.35051546391752575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest (RF)"
      ],
      "metadata": {
        "id": "vsQ7NONdfNTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RF = RandomForestClassifier()\n",
        "RF.fit(X_train_balanced, y_train_balanced)\n",
        "rf_score = RF.score(X_test, y_test)\n",
        "results.append(f\"Balanced data - RF: {rf_score}\")\n",
        "print(f\"RF for balanced data = {rf_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f861b0-b932-4c1b-e42d-519f391b822e",
        "id": "vrZH6PGRfNTt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF for balanced data = 0.3711340206185567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree (DT)"
      ],
      "metadata": {
        "id": "hzzRhgWUfNTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decistion_tree = DecisionTreeClassifier()\n",
        "decistion_tree.fit(X_train_balanced, y_train_balanced)\n",
        "dt_score = decistion_tree.score(X_test, y_test)\n",
        "results.append(f\"Balanced data - DT: {dt_score}\")\n",
        "print(f\"DT for balanced data = {dt_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b7cae4-8341-4fab-d104-91a2a5af22e7",
        "id": "EaSVW55mfNTt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DT for balanced data = 0.25773195876288657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep learning using Neural Network"
      ],
      "metadata": {
        "id": "VubU39Cnj5Sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MultiLabelNN():\n",
        "  # Create 3 layers\n",
        "  # page 5 - Fig 4.\n",
        "  # found shape=(None, 21)\n",
        "  input = Dense(15, input_dim=21, activation=\"relu\", name=\"Input\")\n",
        "  hidden_layer1 = Dense(20, activation=\"relu\", name=\"layer1\")\n",
        "  hidden_layer2 = Dense(20, activation=\"relu\", name=\"layer2\") \n",
        "  hidden_layer3 = Dense(40, activation=\"relu\", name=\"layer3\") \n",
        "  output = Dense(5, activation=\"sigmoid\", name=\"Output\") \n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(input)\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(hidden_layer1)\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(hidden_layer2)\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(hidden_layer3)\n",
        "  model.add(output)\n",
        "\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "p4GnqmMpkBik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.gen_logging_ops import PrintV2\n",
        "\n",
        "X_balanced_new, y_balanced_new = smote.fit_resample(X_balanced, y_balanced.values.ravel())\n",
        "\n",
        "# Re-split the target column back into 5 diseases columns. \n",
        "separated_diseases = []\n",
        "for value in y_balanced_new.ravel():\n",
        "  item = []\n",
        "  for v in value:\n",
        "    item.append(v)\n",
        "  separated_diseases.append(item)\n",
        "\n",
        "y = pd.DataFrame(separated_diseases, columns = ['Insominia', 'shizopherania', 'vascula_demetia', 'MBD', 'Bipolar']).astype('int')\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_balanced_new, y, test_size=0.2)\n",
        "\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.3)\n",
        "\n",
        "model = MultiLabelNN()\n",
        "model.fit(\n",
        "    tf.convert_to_tensor(np.asarray(X_train).astype('int')), \n",
        "    tf.convert_to_tensor(y_train),\n",
        "    epochs=40, \n",
        "    batch_size=10\n",
        ")\n",
        "\n",
        "# test\n",
        "test = model.evaluate(tf.convert_to_tensor(np.asarray(X_test).astype('int')), tf.convert_to_tensor(y_test), batch_size=10)\n",
        "\n",
        "# validation\n",
        "validation = model.evaluate(tf.convert_to_tensor(np.asarray(X_validation).astype('int')), tf.convert_to_tensor(y_validation), batch_size=10)\n",
        "\n",
        "print(f'Training Loss and Accuracy (test): {test}')\n",
        "print(f'Training Loss and Accuracy (validation): {validation}')\n",
        "\n",
        "results.append(f\"Balanced data - Multi-label NN Loss and Accuracy(test): {test}\")\n",
        "results.append(f\"Balanced data - Multi-label NN Loss and Accuracy(validation): {validation}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVEx0iU2khLM",
        "outputId": "f9776476-e92b-49aa-b7ff-71be300070d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "68/68 [==============================] - 1s 3ms/step - loss: 0.7196 - accuracy: 0.3171\n",
            "Epoch 2/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.3909\n",
            "Epoch 3/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.4292\n",
            "Epoch 4/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.4189\n",
            "Epoch 5/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.4528\n",
            "Epoch 6/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.4130\n",
            "Epoch 7/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.4690\n",
            "Epoch 8/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5555 - accuracy: 0.4572\n",
            "Epoch 9/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.4690\n",
            "Epoch 10/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.4484\n",
            "Epoch 11/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.4926\n",
            "Epoch 12/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.4735\n",
            "Epoch 13/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.4336\n",
            "Epoch 14/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.4336\n",
            "Epoch 15/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.4263\n",
            "Epoch 16/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.4454\n",
            "Epoch 17/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.4587\n",
            "Epoch 18/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.4292\n",
            "Epoch 19/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.4218\n",
            "Epoch 20/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.4174\n",
            "Epoch 21/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.4425\n",
            "Epoch 22/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.4469\n",
            "Epoch 23/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.4484\n",
            "Epoch 24/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.3997\n",
            "Epoch 25/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.4587\n",
            "Epoch 26/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.4307\n",
            "Epoch 27/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.4941\n",
            "Epoch 28/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.5074\n",
            "Epoch 29/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.4794\n",
            "Epoch 30/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.4513\n",
            "Epoch 31/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.4617\n",
            "Epoch 32/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.4808\n",
            "Epoch 33/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.4336\n",
            "Epoch 34/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.4307\n",
            "Epoch 35/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.4749\n",
            "Epoch 36/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.4794\n",
            "Epoch 37/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.4454\n",
            "Epoch 38/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.4749\n",
            "Epoch 39/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.4351\n",
            "Epoch 40/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.4425\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.4467\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.5103\n",
            "Training Loss and Accuracy (test): [0.4969610273838043, 0.4467353820800781]\n",
            "Training Loss and Accuracy (validation): [0.48402681946754456, 0.5102880597114563]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single-Label Classification Model on dataset without class imbalance"
      ],
      "metadata": {
        "id": "nk1DeGwPqiXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SingleLabelNN():\n",
        "  # Create 3 layers\n",
        "  # page 5 - Fig 4.\n",
        "  # found shape=(None, 25)\n",
        "  input = Dense(15, input_dim=25, activation=\"relu\", name=\"Input\")\n",
        "  hidden_layer1 = Dense(20, activation=\"relu\", name=\"layer1\")\n",
        "  hidden_layer2 = Dense(40, activation=\"relu\", name=\"layer2\") \n",
        "  hidden_layer3 = Dense(50, activation=\"relu\", name=\"layer3\") \n",
        "  output = Dense(1, activation=\"sigmoid\", name=\"Output\") \n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(input)\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(hidden_layer1)\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(hidden_layer2)\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(hidden_layer3)\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(output)\n",
        "\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "PANO53M4kPtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses_balanced = []\n",
        "\n",
        "for d in diseases:\n",
        "  X = balanced_data.copy()\n",
        "  y = X.pop(d)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "  X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.3)\n",
        "\n",
        "  # balance data with SMOTE\n",
        "  X_train, y_train = smote.fit_resample(X_train, y_train.values.ravel())\n",
        "  X_validation, y_validation = smote.fit_resample(X_validation, y_validation.values.ravel())\n",
        "\n",
        "  model = SingleLabelNN()\n",
        "  model.fit(\n",
        "      tf.convert_to_tensor(np.asarray(X_train).astype('int')), \n",
        "      tf.convert_to_tensor(y_train),\n",
        "      epochs=40, \n",
        "      batch_size=10\n",
        "  )\n",
        "\n",
        "  # test\n",
        "  test = model.evaluate(tf.convert_to_tensor(np.asarray(X_test).astype('int')), tf.convert_to_tensor(y_test), batch_size=10)\n",
        "\n",
        "  # validation\n",
        "  validation = model.evaluate(tf.convert_to_tensor(np.asarray(X_validation).astype('int')), tf.convert_to_tensor(y_validation), batch_size=10)\n",
        "\n",
        "  losses_balanced.append(f'{d} - Training Loss and Accuracy (test): {test}')\n",
        "  losses_balanced.append(f'{d} - Training Loss and Accuracy (validation): {validation}')\n",
        "\n",
        "  results.append(f\"Balanced data - Single-label {d} NN Loss and Accuracy(test): {test}\")\n",
        "  results.append(f\"Balanced data - Single-label {d} NN Loss and Accuracy(validation): {validation}\")\n",
        "\n",
        "for l in losses_balanced:\n",
        "  print(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqQkD_ouHqS3",
        "outputId": "846a3db0-5e39-43fc-afd1-f8d8731c66ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "32/32 [==============================] - 1s 2ms/step - loss: 1.3440 - accuracy: 0.5281\n",
            "Epoch 2/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.7153 - accuracy: 0.4563\n",
            "Epoch 3/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5406\n",
            "Epoch 4/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.5688\n",
            "Epoch 5/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.6531\n",
            "Epoch 6/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6562\n",
            "Epoch 7/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.7125\n",
            "Epoch 8/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.7625\n",
            "Epoch 9/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.8094\n",
            "Epoch 10/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8813\n",
            "Epoch 11/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7781\n",
            "Epoch 12/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7656\n",
            "Epoch 13/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7750\n",
            "Epoch 14/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8031\n",
            "Epoch 15/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7719\n",
            "Epoch 16/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7844\n",
            "Epoch 17/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7781\n",
            "Epoch 18/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7437\n",
            "Epoch 19/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7188\n",
            "Epoch 20/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8000\n",
            "Epoch 21/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8125\n",
            "Epoch 22/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8062\n",
            "Epoch 23/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7906\n",
            "Epoch 24/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8094\n",
            "Epoch 25/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8125\n",
            "Epoch 26/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7656\n",
            "Epoch 27/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8125\n",
            "Epoch 28/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7563\n",
            "Epoch 29/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7812\n",
            "Epoch 30/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8062\n",
            "Epoch 31/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7812\n",
            "Epoch 32/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8125\n",
            "Epoch 33/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8000\n",
            "Epoch 34/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7937\n",
            "Epoch 35/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8250\n",
            "Epoch 36/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2636 - accuracy: 0.9062\n",
            "Epoch 37/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8750\n",
            "Epoch 38/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2592 - accuracy: 0.9187\n",
            "Epoch 39/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.9406\n",
            "Epoch 40/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8406\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 1.0000\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 1.0000\n",
            "Epoch 1/40\n",
            "47/47 [==============================] - 2s 3ms/step - loss: 1.0250 - accuracy: 0.5150\n",
            "Epoch 2/40\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.6510 - accuracy: 0.6432\n",
            "Epoch 3/40\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.7244\n",
            "Epoch 4/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7778\n",
            "Epoch 5/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.8291\n",
            "Epoch 6/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8632\n",
            "Epoch 7/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8846\n",
            "Epoch 8/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3006 - accuracy: 0.8974\n",
            "Epoch 9/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.9017\n",
            "Epoch 10/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.9145\n",
            "Epoch 11/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.9124\n",
            "Epoch 12/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.9038\n",
            "Epoch 13/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8974\n",
            "Epoch 14/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3042 - accuracy: 0.9103\n",
            "Epoch 15/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8974\n",
            "Epoch 16/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.9252\n",
            "Epoch 17/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.9167\n",
            "Epoch 18/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.9081\n",
            "Epoch 19/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.9167\n",
            "Epoch 20/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8846\n",
            "Epoch 21/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.9017\n",
            "Epoch 22/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8889\n",
            "Epoch 23/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2831 - accuracy: 0.9103\n",
            "Epoch 24/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.9124\n",
            "Epoch 25/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.9017\n",
            "Epoch 26/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.9017\n",
            "Epoch 27/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8825\n",
            "Epoch 28/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8846\n",
            "Epoch 29/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2817 - accuracy: 0.9167\n",
            "Epoch 30/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2702 - accuracy: 0.9316\n",
            "Epoch 31/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2826 - accuracy: 0.9124\n",
            "Epoch 32/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8953\n",
            "Epoch 33/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2952 - accuracy: 0.9124\n",
            "Epoch 34/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2876 - accuracy: 0.9274\n",
            "Epoch 35/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8803\n",
            "Epoch 36/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2724 - accuracy: 0.9145\n",
            "Epoch 37/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9444\n",
            "Epoch 38/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.9167\n",
            "Epoch 39/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2918 - accuracy: 0.9359\n",
            "Epoch 40/40\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8846\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2679 - accuracy: 0.9381\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.9216\n",
            "Epoch 1/40\n",
            "39/39 [==============================] - 1s 2ms/step - loss: 1.1240 - accuracy: 0.5105\n",
            "Epoch 2/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.7069 - accuracy: 0.5000\n",
            "Epoch 3/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.7031 - accuracy: 0.5445\n",
            "Epoch 4/40\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.7049 - accuracy: 0.5288\n",
            "Epoch 5/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6989 - accuracy: 0.5262\n",
            "Epoch 6/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.5497\n",
            "Epoch 7/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.7002 - accuracy: 0.4764\n",
            "Epoch 8/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.4948\n",
            "Epoch 9/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5524\n",
            "Epoch 10/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4843\n",
            "Epoch 11/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.5026\n",
            "Epoch 12/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.4791\n",
            "Epoch 13/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5105\n",
            "Epoch 14/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.4895\n",
            "Epoch 15/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5262\n",
            "Epoch 16/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.5471\n",
            "Epoch 17/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.5785\n",
            "Epoch 18/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.5262\n",
            "Epoch 19/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.6073\n",
            "Epoch 20/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6414\n",
            "Epoch 21/40\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.6426 - accuracy: 0.6728\n",
            "Epoch 22/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.7011 - accuracy: 0.5550\n",
            "Epoch 23/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 24/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5262\n",
            "Epoch 25/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5209\n",
            "Epoch 26/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.4921\n",
            "Epoch 27/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6688 - accuracy: 0.5707\n",
            "Epoch 28/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6467 - accuracy: 0.6021\n",
            "Epoch 29/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.6702\n",
            "Epoch 30/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6351 - accuracy: 0.6545\n",
            "Epoch 31/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6492\n",
            "Epoch 32/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.6466\n",
            "Epoch 33/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6149 - accuracy: 0.6571\n",
            "Epoch 34/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.6440\n",
            "Epoch 35/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.6623\n",
            "Epoch 36/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6466\n",
            "Epoch 37/40\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.6832\n",
            "Epoch 38/40\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.6859\n",
            "Epoch 39/40\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.6121 - accuracy: 0.6702\n",
            "Epoch 40/40\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.6545\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.4742\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.6772\n",
            "Epoch 1/40\n",
            "31/31 [==============================] - 2s 2ms/step - loss: 1.2086 - accuracy: 0.4903\n",
            "Epoch 2/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7158 - accuracy: 0.5519\n",
            "Epoch 3/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7132 - accuracy: 0.5584\n",
            "Epoch 4/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5552\n",
            "Epoch 5/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5617\n",
            "Epoch 6/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.5682\n",
            "Epoch 7/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.5812\n",
            "Epoch 8/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.6201\n",
            "Epoch 9/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6573 - accuracy: 0.6039\n",
            "Epoch 10/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.6494\n",
            "Epoch 11/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.6494\n",
            "Epoch 12/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.6429\n",
            "Epoch 13/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6526\n",
            "Epoch 14/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6263 - accuracy: 0.6364\n",
            "Epoch 15/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.6688\n",
            "Epoch 16/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.6623\n",
            "Epoch 17/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.7208\n",
            "Epoch 18/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.6299\n",
            "Epoch 19/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.6429\n",
            "Epoch 20/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.6721\n",
            "Epoch 21/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.6688\n",
            "Epoch 22/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5990 - accuracy: 0.6364\n",
            "Epoch 23/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.6169\n",
            "Epoch 24/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.6104\n",
            "Epoch 25/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.6429\n",
            "Epoch 26/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6346 - accuracy: 0.6331\n",
            "Epoch 27/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.6299\n",
            "Epoch 28/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6266\n",
            "Epoch 29/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.6331\n",
            "Epoch 30/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6266\n",
            "Epoch 31/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.6071\n",
            "Epoch 32/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.5974\n",
            "Epoch 33/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.5909\n",
            "Epoch 34/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.6169\n",
            "Epoch 35/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.6299\n",
            "Epoch 36/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.6364\n",
            "Epoch 37/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5973 - accuracy: 0.6721\n",
            "Epoch 38/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.6981\n",
            "Epoch 39/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.6851\n",
            "Epoch 40/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.6461\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6184 - accuracy: 0.5979\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6194\n",
            "Epoch 1/40\n",
            "32/32 [==============================] - 1s 2ms/step - loss: 0.8182 - accuracy: 0.5000\n",
            "Epoch 2/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.5535\n",
            "Epoch 3/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.6415\n",
            "Epoch 4/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.7327\n",
            "Epoch 5/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7075\n",
            "Epoch 6/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7830\n",
            "Epoch 7/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.6604\n",
            "Epoch 8/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7987\n",
            "Epoch 9/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8082\n",
            "Epoch 10/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8145\n",
            "Epoch 11/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8113\n",
            "Epoch 12/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7956\n",
            "Epoch 13/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8270\n",
            "Epoch 14/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7799\n",
            "Epoch 15/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.3889 - accuracy: 0.8302\n",
            "Epoch 16/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.6289\n",
            "Epoch 17/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7484\n",
            "Epoch 18/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8145\n",
            "Epoch 19/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8082\n",
            "Epoch 20/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8113\n",
            "Epoch 21/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8082\n",
            "Epoch 22/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8176\n",
            "Epoch 23/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8145\n",
            "Epoch 24/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8019\n",
            "Epoch 25/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8082\n",
            "Epoch 26/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7767\n",
            "Epoch 27/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8113\n",
            "Epoch 28/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7862\n",
            "Epoch 29/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8396\n",
            "Epoch 30/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8176\n",
            "Epoch 31/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7893\n",
            "Epoch 32/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7862\n",
            "Epoch 33/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8082\n",
            "Epoch 34/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7925\n",
            "Epoch 35/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7704\n",
            "Epoch 36/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8145\n",
            "Epoch 37/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7893\n",
            "Epoch 38/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7862\n",
            "Epoch 39/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8113\n",
            "Epoch 40/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7893\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2198 - accuracy: 1.0000\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 1.0000\n",
            "Insominia - Training Loss and Accuracy (test): [0.1304149478673935, 1.0]\n",
            "Insominia - Training Loss and Accuracy (validation): [0.12400911003351212, 1.0]\n",
            "shizopherania - Training Loss and Accuracy (test): [0.2679022252559662, 0.938144326210022]\n",
            "shizopherania - Training Loss and Accuracy (validation): [0.2507328987121582, 0.9215686321258545]\n",
            "vascula_demetia - Training Loss and Accuracy (test): [0.6949849128723145, 0.47422680258750916]\n",
            "vascula_demetia - Training Loss and Accuracy (validation): [0.6290737390518188, 0.6772152185440063]\n",
            "MBD - Training Loss and Accuracy (test): [0.6184097528457642, 0.5979381203651428]\n",
            "MBD - Training Loss and Accuracy (validation): [0.6249851584434509, 0.6194030046463013]\n",
            "Bipolar - Training Loss and Accuracy (test): [0.21979738771915436, 1.0]\n",
            "Bipolar - Training Loss and Accuracy (validation): [0.17767038941383362, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GUA4XDilKjq",
        "outputId": "13b33eea-1823-4808-a307-02804d28c682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Imbalanced data - MLP: 0.4742268041237113', 'Imbalanced data - SVM: 0.26804123711340205', 'Imbalanced data - RF: 0.36082474226804123', 'Imbalanced data - DT: 0.32989690721649484', 'Imbalanced data - Multi-label NN Loss and Accuracy(test): [0.6072657704353333, 0.5555555820465088]', 'Imbalanced data - Multi-label NN Loss and Accuracy(validation): [0.6072657704353333, 0.5555555820465088]', 'Imbalanced data - Single-label Insominia NN Loss and Accuracy(test): [6.406447482731892e-06, 1.0]', 'Imbalanced data - Single-label Insominia NN Loss and Accuracy(validation): [7.638313945790287e-06, 1.0]', 'Imbalanced data - Single-label shizopherania NN Loss and Accuracy(test): [0.0012753524351865053, 1.0]', 'Imbalanced data - Single-label shizopherania NN Loss and Accuracy(validation): [0.001699930289760232, 1.0]', 'Imbalanced data - Single-label vascula_demetia NN Loss and Accuracy(test): [0.00010099799692397937, 1.0]', 'Imbalanced data - Single-label vascula_demetia NN Loss and Accuracy(validation): [4.8171961680054665e-05, 1.0]', 'Imbalanced data - Single-label MBD NN Loss and Accuracy(test): [0.0014814190799370408, 1.0]', 'Imbalanced data - Single-label MBD NN Loss and Accuracy(validation): [0.0022191039752215147, 1.0]', 'Imbalanced data - Single-label Bipolar NN Loss and Accuracy(test): [1.0142147402802948e-05, 1.0]', 'Imbalanced data - Single-label Bipolar NN Loss and Accuracy(validation): [2.3933833290357143e-05, 1.0]', 'Imbalanced data - Single-label Insominia NN Loss and Accuracy(test): [0.29466670751571655, 0.9833333492279053]', 'Imbalanced data - Single-label Insominia NN Loss and Accuracy(validation): [0.3229260742664337, 0.9800000190734863]', 'Imbalanced data - Single-label shizopherania NN Loss and Accuracy(test): [0.2520887851715088, 0.9166666865348816]', 'Imbalanced data - Single-label shizopherania NN Loss and Accuracy(validation): [0.4579617381095886, 0.9200000166893005]', 'Imbalanced data - Single-label vascula_demetia NN Loss and Accuracy(test): [0.5493202805519104, 0.699999988079071]', 'Imbalanced data - Single-label vascula_demetia NN Loss and Accuracy(validation): [0.5673412084579468, 0.7400000095367432]', 'Imbalanced data - Single-label MBD NN Loss and Accuracy(test): [0.6212589144706726, 0.6166666746139526]', 'Imbalanced data - Single-label MBD NN Loss and Accuracy(validation): [0.6084908246994019, 0.6499999761581421]', 'Imbalanced data - Single-label Bipolar NN Loss and Accuracy(test): [0.17595838010311127, 0.9750000238418579]', 'Imbalanced data - Single-label Bipolar NN Loss and Accuracy(validation): [0.011681734584271908, 1.0]', 'Imbalanced data - Single-label Insominia NN Loss and Accuracy(test): [0.18677012622356415, 0.9666666388511658]', 'Imbalanced data - Single-label Insominia NN Loss and Accuracy(validation): [0.19448122382164001, 0.9399999976158142]', 'Imbalanced data - Single-label shizopherania NN Loss and Accuracy(test): [0.26019424200057983, 0.9083333611488342]', 'Imbalanced data - Single-label shizopherania NN Loss and Accuracy(validation): [0.25901296734809875, 0.9300000071525574]', 'Imbalanced data - Single-label vascula_demetia NN Loss and Accuracy(test): [0.42520761489868164, 0.824999988079071]', 'Imbalanced data - Single-label vascula_demetia NN Loss and Accuracy(validation): [0.4311346709728241, 0.8199999928474426]', 'Imbalanced data - Single-label MBD NN Loss and Accuracy(test): [0.6460111141204834, 0.5916666388511658]', 'Imbalanced data - Single-label MBD NN Loss and Accuracy(validation): [0.6263187527656555, 0.6499999761581421]', 'Imbalanced data - Single-label Bipolar NN Loss and Accuracy(test): [0.08656129986047745, 0.9916666746139526]', 'Imbalanced data - Single-label Bipolar NN Loss and Accuracy(validation): [0.0928097814321518, 0.9900000095367432]', 'Balanced data - MLP: 0.3917525773195876', 'Balanced data - SVM: 0.41237113402061853', 'Balanced data - RF: 0.3917525773195876', 'Balanced data - MLP: 0.3711340206185567', 'Balanced data - SVM: 0.35051546391752575', 'Balanced data - RF: 0.3711340206185567', 'Balanced data - DT: 0.25773195876288657', 'Balanced data - Multi-label NN Loss and Accuracy(test): [0.4969610273838043, 0.4467353820800781]', 'Balanced data - Multi-label NN Loss and Accuracy(validation): [0.48402681946754456, 0.5102880597114563]', 'Balanced data - Single-label Insominia NN Loss and Accuracy(test): [1.2862596122431569e-05, 1.0]', 'Balanced data - Single-label Insominia NN Loss and Accuracy(validation): [1.5649069609935395e-05, 1.0]', 'Balanced data - Single-label shizopherania NN Loss and Accuracy(test): [0.12457732856273651, 0.946601927280426]', 'Balanced data - Single-label shizopherania NN Loss and Accuracy(validation): [0.2878650724887848, 0.9175257682800293]', 'Balanced data - Single-label vascula_demetia NN Loss and Accuracy(test): [0.5081016421318054, 0.792682945728302]', 'Balanced data - Single-label vascula_demetia NN Loss and Accuracy(validation): [0.5389610528945923, 0.7731958627700806]', 'Balanced data - Single-label MBD NN Loss and Accuracy(test): [0.6248257756233215, 0.6363636255264282]', 'Balanced data - Single-label MBD NN Loss and Accuracy(validation): [0.5933927893638611, 0.6701030731201172]', 'Balanced data - Single-label Bipolar NN Loss and Accuracy(test): [0.00817867275327444, 1.0]', 'Balanced data - Single-label Bipolar NN Loss and Accuracy(validation): [0.011186817660927773, 1.0]', 'Balanced data - Single-label Insominia NN Loss and Accuracy(test): [6.043914169140407e-08, 1.0]', 'Balanced data - Single-label Insominia NN Loss and Accuracy(validation): [3.796158409841155e-08, 1.0]', 'Balanced data - Single-label shizopherania NN Loss and Accuracy(test): [1.151444673538208, 0.8969072103500366]', 'Balanced data - Single-label shizopherania NN Loss and Accuracy(validation): [0.3790818154811859, 0.9306930899620056]', 'Balanced data - Single-label vascula_demetia NN Loss and Accuracy(test): [0.45593079924583435, 0.8041236996650696]', 'Balanced data - Single-label vascula_demetia NN Loss and Accuracy(validation): [0.4355505704879761, 0.8604651093482971]', 'Balanced data - Single-label MBD NN Loss and Accuracy(test): [0.6239315867424011, 0.6185566782951355]', 'Balanced data - Single-label MBD NN Loss and Accuracy(validation): [0.5945229530334473, 0.71875]', 'Balanced data - Single-label Bipolar NN Loss and Accuracy(test): [0.12081816047430038, 0.969072163105011]', 'Balanced data - Single-label Bipolar NN Loss and Accuracy(validation): [0.1419409215450287, 0.9852941036224365]', 'Balanced data - Single-label Insominia NN Loss and Accuracy(test): [1.9881488242390333e-06, 1.0]', 'Balanced data - Single-label Insominia NN Loss and Accuracy(validation): [0.009307920932769775, 0.9929577708244324]', 'Balanced data - Single-label shizopherania NN Loss and Accuracy(test): [0.32496803998947144, 0.9278350472450256]', 'Balanced data - Single-label shizopherania NN Loss and Accuracy(validation): [0.48878198862075806, 0.8834951519966125]', 'Balanced data - Single-label vascula_demetia NN Loss and Accuracy(test): [0.44649001955986023, 0.8247422575950623]', 'Balanced data - Single-label vascula_demetia NN Loss and Accuracy(validation): [0.41071686148643494, 0.8414633870124817]', 'Balanced data - Single-label MBD NN Loss and Accuracy(test): [0.6477910876274109, 0.7216494679450989]', 'Balanced data - Single-label MBD NN Loss and Accuracy(validation): [0.5461817383766174, 0.7112675905227661]', 'Balanced data - Single-label Bipolar NN Loss and Accuracy(test): [2.981138641189318e-05, 1.0]', 'Balanced data - Single-label Bipolar NN Loss and Accuracy(validation): [2.8202632165630348e-05, 1.0]', 'Balanced data - Single-label Insominia NN Loss and Accuracy(test): [0.0003873782989103347, 1.0]', 'Balanced data - Single-label Insominia NN Loss and Accuracy(validation): [0.00020399954519234598, 1.0]', 'Balanced data - Single-label shizopherania NN Loss and Accuracy(test): [0.1907089501619339, 0.969072163105011]', 'Balanced data - Single-label shizopherania NN Loss and Accuracy(validation): [0.2054731398820877, 0.9528301954269409]', 'Balanced data - Single-label vascula_demetia NN Loss and Accuracy(test): [0.44660675525665283, 0.8659793734550476]', 'Balanced data - Single-label vascula_demetia NN Loss and Accuracy(validation): [0.5007085204124451, 0.7792207598686218]', 'Balanced data - Single-label MBD NN Loss and Accuracy(test): [0.6173642873764038, 0.6597937941551208]', 'Balanced data - Single-label MBD NN Loss and Accuracy(validation): [0.49755334854125977, 0.746268630027771]', 'Balanced data - Single-label Bipolar NN Loss and Accuracy(test): [0.0004806009237654507, 1.0]', 'Balanced data - Single-label Bipolar NN Loss and Accuracy(validation): [0.00047653037472628057, 1.0]', 'Balanced data - Single-label Insominia NN Loss and Accuracy(test): [3.632477501014364e-07, 1.0]', 'Balanced data - Single-label Insominia NN Loss and Accuracy(validation): [1.1814235989504596e-07, 1.0]', 'Balanced data - Single-label shizopherania NN Loss and Accuracy(test): [0.39889031648635864, 0.907216489315033]', 'Balanced data - Single-label shizopherania NN Loss and Accuracy(validation): [0.2581104636192322, 0.9242424368858337]', 'Balanced data - Single-label vascula_demetia NN Loss and Accuracy(test): [0.6388353109359741, 0.7835051417350769]', 'Balanced data - Single-label vascula_demetia NN Loss and Accuracy(validation): [0.4831848442554474, 0.8390804529190063]', 'Balanced data - Single-label MBD NN Loss and Accuracy(test): [0.6200463771820068, 0.6597937941551208]', 'Balanced data - Single-label MBD NN Loss and Accuracy(validation): [0.5315588116645813, 0.7394366264343262]', 'Balanced data - Single-label Bipolar NN Loss and Accuracy(test): [0.0017625261098146439, 1.0]', 'Balanced data - Single-label Bipolar NN Loss and Accuracy(validation): [0.0015771490288898349, 1.0]', 'Balanced data - Single-label Insominia NN Loss and Accuracy(test): [0.1304149478673935, 1.0]', 'Balanced data - Single-label Insominia NN Loss and Accuracy(validation): [0.12400911003351212, 1.0]', 'Balanced data - Single-label shizopherania NN Loss and Accuracy(test): [0.2679022252559662, 0.938144326210022]', 'Balanced data - Single-label shizopherania NN Loss and Accuracy(validation): [0.2507328987121582, 0.9215686321258545]', 'Balanced data - Single-label vascula_demetia NN Loss and Accuracy(test): [0.6949849128723145, 0.47422680258750916]', 'Balanced data - Single-label vascula_demetia NN Loss and Accuracy(validation): [0.6290737390518188, 0.6772152185440063]', 'Balanced data - Single-label MBD NN Loss and Accuracy(test): [0.6184097528457642, 0.5979381203651428]', 'Balanced data - Single-label MBD NN Loss and Accuracy(validation): [0.6249851584434509, 0.6194030046463013]', 'Balanced data - Single-label Bipolar NN Loss and Accuracy(test): [0.21979738771915436, 1.0]', 'Balanced data - Single-label Bipolar NN Loss and Accuracy(validation): [0.17767038941383362, 1.0]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DjVL6o4ZypeR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}